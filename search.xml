<?xml version="1.0" encoding="utf-8"?>
<search> 
  
    
    <entry>
      <title><![CDATA[正则化手段：Dropout]]></title>
      <url>/articles/ml-dl-dropout.html</url>
      <content type="html"><![CDATA[<p>Dropout是一种常见的正则化方法。它借用了集成学习的思想，近似实现了同时训练大量网络结构，并通过集成得出预测结果的功能。由于含有集成环节，Dropout可以有效地避免过拟合。<br><a id="more"></a></p>
<h1 id="一、Dropout的基本思想"><a href="#一、Dropout的基本思想" class="headerlink" title="一、Dropout的基本思想"></a>一、Dropout的基本思想</h1><p>Dropout要解决的问题是：在同一个神经网络模型中，有没有可能通过一定的手段模拟出多个网络模型的效果，从而提升模型精度？针对这个问题，Dropout巧妙利用了一个事实：一个神经网络模型中，通过屏蔽部分神经元，就可以构建出不同的神经网络模型。如下图，原始神经网络的输入层有2个神经元，隐藏层有2个神经元。通过把部分神经元删去，我们可以得到$2^4=16$种不同的网络。当然，其中一部分网络是无效网络，例如第4行的所有网络，但这并不会造成太大影响，因为当特征数、网络层数增加的时候，这种无效网络的比例会急剧下降。</p>
<div align="center"><br><img src="/images/ml-dl-dropout/subnetworks.jpg" alt=""><br></div>

<p>和一般的Bagging模型不同，上述的所有网络只是网络结构不同，但所有的参数都是共享的。因此，这种方法的效果比直接训练同样数量的独立网络要差一些。但是，我们应该注意到，当有$n$个特征时，不同结构的数量可以达到$2^n$个！对于如此巨大的网络数量，训练独立网络本身就是一件不可能的事情。所以，结构不同、参数共享的网络已经是一种非常好的实现方法了。另外，指数级别的网络数量也保证了共享参数的网络能达到好的预测效果。</p>
<p>接下来，Dropout还需要解决如下问题：</p>
<ol>
<li>如何同时训练不同结构的（参数共享）的网络？</li>
<li>如何对不同结构的网络进行集成，从而得到预测结果？</li>
</ol>
<p>我们在下一节讨论这两个问题。</p>
<h1 id="二、Dropout的训练和预测方法"><a href="#二、Dropout的训练和预测方法" class="headerlink" title="二、Dropout的训练和预测方法"></a>二、Dropout的训练和预测方法</h1><h2 id="2-1-训练"><a href="#2-1-训练" class="headerlink" title="2.1 训练"></a>2.1 训练</h2><p>一般来说，神经网络的训练会采用随机梯度下降法。该方法每次训练会选取一个batch的数据，通过BP算法计算梯度，并更新参数。为了训练不同结构的神经网络，我们需要屏蔽其中的一些神经元。实际上，神经网络的特殊结构使得我们屏蔽相关的神经元非常简单——只需要在该神经元的输出上乘以0即可。如下图，我们在输入层和隐含层的每个神经元上面乘以一个系数$\mu$，$\mu$只能为0或1。那么，$\mu=1$时，该神经元可以正常输出，而$\mu=0$时，该神经元就会被屏蔽。</p>
<div align="center"><br><img src="/images/ml-dl-dropout/masking.jpg" alt=""><br></div>

<p>值得注意的是，屏蔽神经元并不意味着我们会把该神经元的内容清空。神经元内部的参数仍然是保留的，只是在本次训练中，它的输出被外部变量$\mu=0$屏蔽了。这样，我们就能够实现一个子网络的训练。</p>
<p>那么，屏蔽层$\mu$的数值是如何确定的呢？这就是在深度学习框架中的常见超参数：keep probability，即保留概率，在各种框架中一般记作keep_prob。在每次训练中，各个屏蔽系数$\mu$独立设置，设置为1的概率为keep_prob，设置为0的概率则为1-keep_prob。由此可见，保留概率为1时，神经网络不采用Dropout，而保留概率为0时，神经网络就不再工作（因为所有神经元都被屏蔽）。一般来说，保留概率可以选取0.5~0.8。</p>
<p>由于参数共享，每次训练过程尽管只针对某一个网络，但所有网络的参数（除了本次被屏蔽的神经元参数）都会同步更新。Dropout的训练方法与不含Dropout的训练方法的区别在于，训练时会考虑到不同网络结构下最优参数的设置，因此最终训练出来的参数在每种网络结构下都会有一定的效果。可以看出，这种方法能够有效地避免过拟合，因为过拟合的本质在于网络参数对误差过于敏感，而一组参数如果在不同的网络结构下都能取得不错的效果，那么这组参数发生过拟合的概率也会降低。</p>
<h2 id="2-2-预测"><a href="#2-2-预测" class="headerlink" title="2.2 预测"></a>2.2 预测</h2><p>集成预测方法一般需要计算每种网络结构下的预测值，并做加权平均。可惜的是，由于网络结构有$2^n$种，我们无法逐个计算。与训练不同的地方在于，训练时我们可以通过训练一种网络结构，实现其他网络结构的参数同步更新，而预测的时候，我们无法通过某一个网络结构下的预测结果，获取其他网络结构下的预测结果。实际上，到目前为止还没有什么方法能在数学意义上保证有效的预测，所以只能采用一些启发式的方法。</p>
<p>一种最简单的思路是随机选取有限数量（如10~20组）网络，分别进行预测，再对预测结果按照概率进行加权平均。这种方法看上去只利用了很少的网络结构，但在实践中可以运行得很好。另一种方法是采用几何平均值代替算术加权平均值，作为Bagging后的结果。当然，几何平均值并不比算术平均值更容易求解，但是我们可以用一种有效的方法近似处理：只需考虑所有元素均未屏蔽的网络，在每个神经元的输出时乘以保留概率，最终得到的输出即可近似表示Bagging后的预测值。在一定条件下，可以证明这样处理得到的结果即为几何平均值，但在更多情况下，这只是一种简单的近似。</p>
<h2 id="2-3-Dropout的实用变形"><a href="#2-3-Dropout的实用变形" class="headerlink" title="2.3 Dropout的实用变形"></a>2.3 Dropout的实用变形</h2><p>根据前两个小节的结果，我们可以看出Dropout的应用方法：</p>
<ol>
<li>在训练时，每个神经元以keep_prob的概率正常输出，以1-keep_prob的概率输出0，然后运行BP算法进行梯度计算。</li>
<li>在预测时，每个神经元的输出乘以keep_prob后，进入下一层。</li>
</ol>
<p>为了更加方便地使用Dropout，我们通常做如下变形：</p>
<ol>
<li>在训练时，每个神经元以keep_prob的概率放大1/keep_prob倍输出。以1-keep_prob的概率输出0。这样，每个神经元的输出期望值和没有Dropout时的正常输出值相等。</li>
<li>在预测时，直接按照全网络进行预测即可。</li>
</ol>
<p>这个变形实际上把预测时乘以keep_prob的过程转移到了训练中。这样，Dropout就完全成为训练参数。由于在深度学习中，训练和预测通常是分开的，这么处理使得预测时完全不用考虑Dropout的问题，为程序编写和运行带来了方便。</p>
<p>作为小结，Dropout是深度学习中的常用技巧，通过同时训练结构不同、参数共享的网络，模拟Bagging的效果。同时，由于训练时每个神经元的输出不确定可能为正常值，也可能为零，因此训练出来的网络对于误差有更强的适应性，从而有效避免过拟合。Dropout原理的简易性使其可以适应于各种结构的网络。但应该注意到，Dropout本质上是一种正则化手段，因此引入Dropout有可能会降低模型的训练速度和精度。</p>
]]></content>
      
        <categories>
            
            <category> 机器学习 </category>
            
            <category> 深度学习相关 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> dropout </tag>
            
            <tag> 过拟合 </tag>
            
            <tag> bagging </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[支持向量机：核方法]]></title>
      <url>/articles/ml-svm-kernel.html</url>
      <content type="html"><![CDATA[<p>利用支持向量机的对偶形式，可以把支持向量机推广到非线性模型中。由于对偶形式中仅出现了自变量的内积形式，因此在非线性支持向量机中，我们甚至不用定义具体的非线性映射，只需要定义“非线性内积”，也就是核函数。核方法使得非线性支持向量机仍然能用凸二次规划的方法来求解。<br><a id="more"></a></p>
<h1 id="一、核方法的基本思路"><a href="#一、核方法的基本思路" class="headerlink" title="一、核方法的基本思路"></a>一、核方法的基本思路</h1><h2 id="1-1-非线性支持向量机"><a href="#1-1-非线性支持向量机" class="headerlink" title="1.1 非线性支持向量机"></a>1.1 非线性支持向量机</h2><p>线性支持向量机的基本思路是求一个分离超平面$w^Tx+b=0$，然后利用这个超平面将待预测样本空间分成两类。但实际问题中，常常会出现正负样本无法通过超平面分离的情形。非线性支持向量机的思路是通过一个非线性曲面将正负样本分离：</p>
<p>\[<br>\hat{y} = w^T\phi(x) + b<br>\]</p>
<p>当$\hat{y}&gt;0$时即为正样本，$\hat{y}&lt;0$时即为负样本。这里$\phi(\cdot)$是一个给定的函数。此时，支持向量机的问题可以写成：<br>\[<br>\min_{w,b} C\sum_{i=1}^N\xi_i + \frac{1}{2}w^Tw \\<br>\text{s.t. } y_i\left( w^T\phi(x_i) + b \right) \geq 1 \\<br>\xi_i \geq 0<br>\]</p>
<p>注意到$\phi(\cdot)$是给定的函数，$\phi(x_i)$的值也是给定的，可以看出，非线性支持向量机并没有在决策变量层面引入非线性，因此仍然是一个凸二次规划问题。</p>
<h2 id="1-2-核方法"><a href="#1-2-核方法" class="headerlink" title="1.2 核方法"></a>1.2 核方法</h2><p>为了引入核方法，我们首先给出非线性支持向量机的对偶形式：<br>\[<br>\min \frac{1}{2}\sum_{i=1}^N\sum_{j=1}^N\alpha_i\alpha_jy_iy_j \phi(x_i)^T\phi(x_j) - \sum_{i=1}^N\alpha_i \\<br>\text{s.t. } \sum_{i=1}^N\alpha_iy_i=0 \\<br>0\leq \alpha_i \leq C<br>\]</p>
<p>在该形式下，支持向量机的预测为：<br>\[<br>\hat{y} = \sum_{i=1}^N\alpha_iy_i\phi(x_i)^T\phi(x) + b<br>\]</p>
<p>这里，线性支持向量机的$x_i^Tx_j$被替换为$\phi(x_i)^T\phi(x_j)$，其余部分都没有变。我们定义一个新的函数$K$：<br>\[<br>K(x,z) = \phi(x)^T\phi(z)<br>\]</p>
<p>这样，非线性支持向量机就可以写成如下形式：<br>\[<br>\min \frac{1}{2}\sum_{i=1}^N\sum_{j=1}^N\alpha_i\alpha_jy_iy_j K(x_i, x_j) - \sum_{i=1}^N\alpha_i \\<br>\text{s.t. } \sum_{i=1}^N\alpha_iy_i=0 \\<br>0\leq \alpha_i \leq C<br>\]</p>
<p>支持向量机的预测为：<br>\begin{equation} \label{eq:svm-kernel-predict}<br>\hat{y} = \sum_{i=1}^N\alpha_iy_iK(x_i,x) + b<br>\end{equation}</p>
<p>这里，函数$K(\cdot,\cdot)$被称为<strong>核函数</strong>。</p>
<p>很容易注意到，在支持向量机的对偶形式中，从训练到预测，我们都只需要用到核函数$K$，而不需要用到映射$\phi$。这就意味着，<strong>在非线性支持向量机中，只需要知道核函数就可以进行训练和预测，完全不需要定义非线性映射$\phi$</strong>。这一性质非常重要，因为在具体的问题中，映射$\phi$的定义相对困难，没有很明确的方法，而核函数$K$的定义和计算则相对容易。</p>
<p>核方法的基本思路即在于：只定义核函数$K$，不定义映射$\phi$，通过求解相应的二次规划，进行训练和预测。这种方法使得线性支持向量机的相关算法可以无缝推广到非线性支持向量机，从而拓宽了支持向量机的应用范围。</p>
<h1 id="二、常用的核函数"><a href="#二、常用的核函数" class="headerlink" title="二、常用的核函数"></a>二、常用的核函数</h1><p>这里有一个不大的问题：给定一个函数$K$，它是否一定是某个映射$\phi$所对应的核函数？答案是否定的，即核函数需要满足一定的条件。我们可以通过一定的方法判断一个函数是否为核函数（此处不再介绍），但实际应用中，我们通常在一些已经被验证为核函数的函数族中选取合适的函数。</p>
<h2 id="2-1-多项式核函数"><a href="#2-1-多项式核函数" class="headerlink" title="2.1 多项式核函数"></a>2.1 多项式核函数</h2><p>多项式核函数的基本形式为：<br>\[<br>K(x,z) = \left(1 + x^Tz\right)^p<br>\]</p>
<p>这里有一个特例：当$p=1$时，$K(x,z)=1+x^Tz$，这一形式和内积$x^Tz$非常相似。实际上，此时求出的结果和线性支持向量机的求解结果是相同的，因为多出来的$1$可以看做常数项，会被吸收进常数项$b$中。</p>
<h2 id="2-2-高斯核函数"><a href="#2-2-高斯核函数" class="headerlink" title="2.2 高斯核函数"></a>2.2 高斯核函数</h2><p>高斯核函数的定义为：<br>\[<br>K(x,z) = \exp\left(-\frac{(x-z)^T(x-z)}{2\sigma^2}\right)<br>\]</p>
<p>这一核函数反映了样本点$x$和$z$的距离，距离越近则值越大。注意到支持向量机的预测式\eqref{eq:svm-kernel-predict}，$x_i$与$x$距离越近，$K(x_i,x)$越大，$y_i$的值对$\hat{y}$的影响越大。由此可见，高斯核函数是一种基于局部性的方法。而参数$\sigma$是调整局部性强弱的参数。$\sigma$越小，预测越偏重于附近的数据，$\sigma$越大，预测越偏重于全局。</p>
<h1 id="三、小结"><a href="#三、小结" class="headerlink" title="三、小结"></a>三、小结</h1><p>这里我们用在吴恩达的<a href="https://www.coursera.org/learn/machine-learning/" target="_blank" rel="external">机器学习</a>课程中关于不同模型应用范围的阐述作为本文的结尾。</p>
<p>假设特征数量为$n$，训练样本数量为$m$，那么根据$n$和$m$的大小关系，可以按如下方法选择训练模型：</p>
<ol>
<li>$n$相对于$m$很大时，说明样本较少，需要选择简单的模型，通常使用Logistic回归，或线性支持向量机。如果使用核方法引入非线性，可能会造成过拟合。</li>
<li>$n$和$m$大小相当，或$m$略大于$n$时，可以使用非线性支持向量机；</li>
<li>$n$较小，而$m$较大时，这时可以手动增加特征（如原始特征的非线性变换），然后使用Logistic回归或线性支持向量机。这里的考虑因素主要是核方法会引入更多的计算，增加训练成本。而线性方法训练会更快。</li>
</ol>
]]></content>
      
        <categories>
            
            <category> 机器学习 </category>
            
            <category> 模型 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 支持向量机 </tag>
            
            <tag> SVM </tag>
            
            <tag> 对偶 </tag>
            
            <tag> 核方法 </tag>
            
            <tag> 非线性支持向量机 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[支持向量机：对偶形式]]></title>
      <url>/articles/ml-svm-dual.html</url>
      <content type="html"><![CDATA[<p>支持向量机的原始形式为二次规划，这是一种典型的凸规划，也满足强对偶定理。支持向量机的对偶形式仍然为凸二次规划。对偶形式的主要优点除了计算以外，还在于其易于推广到非线性支持向量机。本节介绍对偶形式的构造，以及如何根据对偶问题的解还原出原始问题的解。<br><a id="more"></a></p>
<h1 id="一、对偶形式的构造"><a href="#一、对偶形式的构造" class="headerlink" title="一、对偶形式的构造"></a>一、对偶形式的构造</h1><p>考虑支持向量机的原始形式：<br>\[<br>\min_{w,b,\xi} C \sum_{i=1}^N\xi_i + \frac{1}{2}w^Tw \\<br>\text{s.t. } y_i\left(w^Tx_i+b\right) \geq 1 - \xi_i \\<br>\xi_i \geq 0<br>\]</p>
<p>其拉格朗日函数为：<br>\[<br>L(w,b, \xi, \alpha, \beta) = C \sum_{i=1}^N\xi_i + \frac{1}{2}w^Tw - \sum_{i=1}^N\alpha_i\left[y_i\left(w^Tx_i+b\right) - 1 + \xi_i \right] - \sum_{i=1}^N\beta_i\xi_i<br>\]</p>
<p>可以证明，原始问题等价于如下形式：<br>\[<br>p^* = \min_{w,b,\xi} \max_{\alpha\geq 0, \beta \geq 0} L(w,b,\xi,\alpha, \beta)<br>\]</p>
<p>而对偶问题则为：<br>\[<br>d^* = \max_{\alpha\geq 0, \beta \geq 0} \min_{w,b,\xi} L(w,b,\xi,\alpha, \beta)<br>\]</p>
<p>为了简化问题，下面我们求解对偶问题的内部优化。在固定了$\alpha,\beta$后，内部优化问题实际上是一个无约束二次规划问题，简单地令其对$w,b,\xi$的导数为零，可以得到：<br>\[<br>w=\sum_{i=1}^N\alpha_iy_ix_i \\<br>\sum_{i=1}^N\alpha_iy_i=0 \\<br>\alpha_i+\beta_i=C<br>\]</p>
<p>将这些式子代入$L$的表达式，得到：<br>\[<br>\min_{w,b,\xi} L(w,b,\xi,\alpha,\beta) = -\frac{1}{2} \sum_{i=1}^N\sum_{j=1}^N \alpha_i\alpha_jy_iy_jx_i^Tx_j + \sum_{i=1}^N\alpha_i<br>\]</p>
<p>于是对偶问题为：<br>\[<br>\max_{\alpha\geq 0, \beta \geq 0} -\frac{1}{2} \sum_{i=1}^N\sum_{j=1}^N \alpha_i\alpha_jy_iy_jx_i^Tx_j +\sum_{i=1}^N\alpha_i\\<br>\text{s.t. } \sum_{i=1}^N\alpha_iy_i=0 \\<br>\alpha_i+\beta_i=C<br>\]</p>
<p>注意到$\beta$在上面的优化问题中等价于保证$\alpha_i \leq C$，可以消去$\beta$，并把上述问题改写为：<br>\[<br>\min_{\alpha} \frac{1}{2} \sum_{i=1}^N\sum_{j=1}^N \alpha_i\alpha_jy_iy_jx_i^Tx_j - \sum_{i=1}^N\alpha_i \\<br>\text{s.t. } \sum_{i=1}^N\alpha_iy_i=0 \\<br>0 \leq\alpha_i\leq C<br>\]</p>
<p>这样我们就得到<strong>支持向量机的对偶形式</strong>。可以看出，支持向量机的对偶形式仍然为二次规划。和原始形式相同，这个二次规划也是一个凸规划，这一事实可以从下述等式中看出：<br>\[<br>\sum_{i=1}^N\sum_{j=1}^N \alpha_i\alpha_jy_iy_jx_i^Tx_j = \alpha^TA^TA\alpha<br>\]</p>
<p>其中$A=\left[y_1x_1,y_2x_2,\dots,y_Nx_N\right]$是一个$D\times N$的矩阵（D为特征的维数）。而$A^TA$是一个半正定矩阵，因此该二次规划为凸规划。</p>
<h1 id="二、对偶问题的解与原始问题的关系"><a href="#二、对偶问题的解与原始问题的关系" class="headerlink" title="二、对偶问题的解与原始问题的关系"></a>二、对偶问题的解与原始问题的关系</h1><h2 id="2-1-基本思路"><a href="#2-1-基本思路" class="headerlink" title="2.1 基本思路"></a>2.1 基本思路</h2><p>根据强对偶定理，对偶问题的最优解与原始问题的最优解相等。因此，求得对偶问题的解，即可得到原始问题的解。在前面的分析中，我们已经看到了$w$与对偶解$\alpha$之间的关系：<br>\[<br>w=\sum_{i=1}^N\alpha_iy_ix_i<br>\]</p>
<p>得到了$w$后，还需要确定原始问题的$b$。为此，考虑原始问题的约束：<br>\[<br>y_i\left(w^Tx_i+b\right) \geq 1 - \xi_i \\<br>\xi_i \geq 0<br>\]</p>
<p>如果对于某个$i$，这个约束起作用，即：<br>\[<br>y_i\left(w^Tx_i+b\right) = 1 - \xi_i \\<br>\xi_i = 0<br>\]</p>
<p>那么我们就有：<br>\[<br>b = 1 / y_i - w^Tx_i = y_i - w^Tx_i = y_i - \sum_{i=j}^N\alpha_jy_jx_j^Tx_i<br>\]</p>
<p>从而可以求得$b$。由此可见，寻找起作用约束是确定$b$的关键环节。那么，我们需要考虑两个问题：</p>
<ol>
<li>起作用约束一定存在吗？如果不存在如何处理？</li>
<li>起作用约束是否唯一？如果不唯一如何处理？</li>
</ol>
<p>我们首先回答第2个问题：起作用约束不一定唯一，但不同的起作用约束计算出来的$b$是相等的。这是因为，上述起作用约束构成了对$b$的等式约束，如果两个等式约束的结果不同，就会造成矛盾。所以，如果能找到一个$i$使得$0&lt;\alpha_i&lt;C$，就可以放心地利用该样本算出相应的$b$。</p>
<p>对于第1个问题，一般采用互补松弛定理来处理。下面我们考虑硬间隔和软间隔两种情况。</p>
<h2 id="2-2-硬间隔下的支持向量机"><a href="#2-2-硬间隔下的支持向量机" class="headerlink" title="2.2 硬间隔下的支持向量机"></a>2.2 硬间隔下的支持向量机</h2><p>所谓硬间隔，即为线性可分场景下的支持向量机，即：<br>\[<br>\min_{w,b} \frac{1}{2}w^Tw \\<br>\text{s.t. } y_i\left(w^Tx_i+b\right) \geq 1<br>\]</p>
<p>它对应于$C$为无穷大的情形。此时，对偶问题的约束由$0\leq \alpha_i \leq C$变为$\alpha_i\geq 0$，其余约束不变。这种情形相对简单，因此先予以讨论。</p>
<p>根据互补松弛定理我们知道，如果对偶问题的解中有一个$\alpha_i$满足$\alpha_i&gt;0$，那么原始问题中对应的约束则起作用。所以，只要找到一个$\alpha_i&gt;0$即可。那么，是否有可能所有$\alpha_i$均为0呢？答案是否定的，否则我们可以得到$w=\sum_{i=1}^N\alpha_iy_ix_i=0$，从而原问题中的约束$y_i\left(w^Tx_i+b\right) \geq 1$变为$y_ib\geq 1$。而$b$是固定值，在二类分类问题中，训练样本$y_i$应部分为1，部分为-1，不可能做到$y_ib\geq 1,\forall i$，因此产生矛盾。从而，必然存在$\alpha_i&gt;0$，即起作用约束必然存在。<strong>显然，$\alpha_i&gt;0$对应的样本点$i$即为支持向量</strong>。</p>
<h2 id="2-3-软间隔下的支持向量机"><a href="#2-3-软间隔下的支持向量机" class="headerlink" title="2.3 软间隔下的支持向量机"></a>2.3 软间隔下的支持向量机</h2><p>软间隔对应的是一般的支持向量机，此时通过类似的互补松弛分析可以得知，如果存在$0&lt;\alpha_i<c$，则对应的两个约束$y\_i\\left(w^tx\_i+b\\right) 1="" =="" -="" \\xi\_i$和$\\xi\_i="0$均起作用，从而可以求得$b$。同样地，可以证明必然存在$i$使得$\\alpha\_i">0$，这些样本也称为<strong>支持向量</strong>。</c$，则对应的两个约束$y\_i\\left(w^tx\_i+b\\right)></p>
<p>然而，在软间隔下，我们只能保证必然存在$\alpha_i$使得$\alpha_i&gt;0$，但不能保证存在$i$使得$0&lt;\alpha_i&lt;C$。换句话说，<strong>有可能不存在样本点$i$，使两个约束$y_i\left(w^Tx_i+b\right) = 1 - \xi_i$和$\xi_i = 0$同时起作用。</strong>这种情况下，$b$的取值在一定范围内是任意的。不同的$b$会对应不同的$\xi_i$，但因为目标函数中只有求和项$\sum_{i=1}^N\xi_i$，由$b$的变化造成的$\xi_i$的变化会在求和中被抵消。也就是说，不同的$b$对应的目标函数是不变的。究其原因，是<strong>软间隔下的支持向量机可能存在不唯一的最优解</strong>。</p>
<p>这个时候，通常的做法是在$\alpha_i=C$的样本（这些样本也是支持向量，因为满足$\alpha_i&gt;0$）中，任意选择样本$i$，令$\xi_i=0$，从而得出相应的$b$。或者对所有的满足$\alpha_i=C$的约束采取这样的操作，将所得到的$b$取平均，从而得到“接近中心”的分离超平面。</p>
<h1 id="三、小结"><a href="#三、小结" class="headerlink" title="三、小结"></a>三、小结</h1><p>最后，我们总结利用对偶方法求解支持向量机的步骤：</p>
<ol>
<li>列出其对偶形式并求解出最优的$\alpha$：<br>\[<br>\min_{\alpha} \frac{1}{2} \sum_{i=1}^N\sum_{j=1}^N \alpha_i\alpha_jy_iy_jx_i^Tx_j - \sum_{i=1}^N\alpha_i \\<br>\text{s.t. } \sum_{i=1}^N\alpha_iy_i=0 \\<br>0 \leq\alpha_i\leq C<br>\]</li>
<li>找到起作用约束$i$，计算系数$b = 1 / y_i - w^Tx_i = y_i - w^Tx_i = y_i - \sum_{i=1}^N\alpha_jy_jx_j^Tx_i$.</li>
<li>对于给定的样本$x$，预测：<br>\[<br>\hat{y}=w^Tx+b=\sum_{i=1}^N\alpha_iy_ix_i^Tx+b<br>\]</li>
</ol>
<p>值得注意的是，在第3步中，我们并没有显式地计算出$w$，而是将$w=\sum_{i=1}^N\alpha_iy_ix_i$代入到$\hat{y}=w^Tx+b$计算预测值。这实际上体现了对偶方法的一个很重要的性质：<strong>在所有步骤中，涉及到自变量的部分均以内积$x_i^Tx_j$或$x_i^Tx$的形式出现，不含有其他对自变量的操作</strong>。这个性质使得支持向量机非常容易推广到非线性的情形：<strong>只要我们能定义一种新的“内积”来取代$x_i^Tx_j$的形式，就可以用相同的算法（凸二次规划）来处理非线性分类问题。</strong>这也是支持向量机的一个重要的优势。</p>
]]></content>
      
        <categories>
            
            <category> 机器学习 </category>
            
            <category> 模型 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 支持向量机 </tag>
            
            <tag> SVM </tag>
            
            <tag> 对偶 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[支持向量机：构造]]></title>
      <url>/articles/ml-svm-construction.html</url>
      <content type="html"><![CDATA[<p>支持向量机（Support Vector Machine, SVM）的主要思想是在分类问题中使不同类别之间的“间隔”最大。所谓支持向量，即在分类问题中最接近边界的样本，这些样本会影响到分类超平面的构造。可以有两种方式构造支持向量机，一种是直接基于间隔最大化思想，另一种则是基于一种特殊的损失函数（合页损失函数）。从损失函数的角度理解，支持向量机并不比Logistic回归更强大，当然，支持向量机的核心优势并不在此。<br><a id="more"></a></p>
<p>考虑一个二类分类问题，给定特征$x$，预测分类值$y\in \{-1,1\}$。线性支持向量机的目标是找到一个超平面$w^Tx+b=0$，然后对于任意$x$，给出预测值$y=\text{sgn}\{w^Tx+b\}$。换句话说，线性支持向量机根据样本点$x$与超平面$w^Tx+b=0$的关系来决定该点的分类。</p>
<h1 id="一、基于距离的构造"><a href="#一、基于距离的构造" class="headerlink" title="一、基于距离的构造"></a>一、基于距离的构造</h1><h2 id="1-1-线性可分情形"><a href="#1-1-线性可分情形" class="headerlink" title="1.1 线性可分情形"></a>1.1 线性可分情形</h2><p>考虑一组训练数据$\left(x^{(i)},y^{(i)}\right),i=1,2,\dots,N$，其中$y^{(i)}\in\{-1,1\}$。我们假设数据是<strong>线性可分</strong>的，也就是说，存在向量$w$和常数$b$，满足如下条件：<br>\[<br>\left\{<br>\begin{split}<br>w^Tx^{(i)}+b &lt; 0, &amp;\forall i\text{ s.t. }y^{(i)}=-1 \\<br>w^Tx^{(i)}+b &gt; 0, &amp;\forall i\text{ s.t. }y^{(i)}=1<br>\end{split}<br>\right.<br>\]</p>
<p>在这种情况下，我们认为数据被超平面$w^Tx+b=0$分离。同时，注意到$(w,b)$和$(\lambda w, \lambda b),\lambda \neq 0$代表了相同的超平面，因此，我们可以对$(w,b)$进行齐次放缩，而不影响结果。通过合理的放缩，可以得到如下条件：<br>\[<br>\left\{<br>\begin{split}<br>w^Tx^{(i)}+b \leq -1, &amp;\forall i\text{ s.t. }y^{(i)}=-1 \\<br>w^Tx^{(i)}+b \geq 1, &amp;\forall i\text{ s.t. }y^{(i)}=1<br>\end{split}<br>\right.<br>\]</p>
<p>这个条件又等价于如下条件：<br>\[<br>y^{(i)}\left(w^Tx^{(i)}+b\right) \geq 1<br>\]</p>
<p>注意到数据集$\left(x^{(i)}, y^{(i)} \right)$是已知的，上述条件是$(w,b)$的线性约束。</p>
<p>一般来说，满足约束的超平面有很多，支持向量机要解决的问题是：什么样的超平面是最合理的？而它给出的方案是：让超平面两边的点离超平面都足够远。为此，我们先来看如何衡量一个点到超平面的距离。</p>
<p>首先取超平面上的一点$\tilde{x}$，即满足$w^T\tilde{x}+b=0$，考虑超平面外的一点$x$，我们只需要计算向量$x-\tilde{x}$在超平面法向的投影即可。而该投影可以通过与法向单位向量$\frac{w}{\lVert w\rVert}$的内积得到：<br>\[<br>dist(x) = \frac{w^T(x-\tilde{x})}{\lVert w \rVert} = \frac{w^Tx+b}{\lVert w \rVert}<br>\]</p>
<p>其中，后一个等式用到了$\tilde{x}$在超平面上的条件，即$w^T\tilde{x}+b=0$。这是一个有向距离，即$x$在超平面两边时，所得到距离的符号不同。注意到$x$在超平面两边时，$y$分别为$\pm 1$，因此正确的距离应该为$\frac{y\left(w^Tx+b\right)}{\lVert w \rVert}$。由此，为了最大化距离，我们需要求解如下优化问题：</p>
<p>\[<br>\max_{w,b} \min_{i} \frac{y^{(i)}\left(w^Tx^{(i)}+b\right)}{\lVert w \rVert} \\<br>\text{s.t. } y^{(i)}\left(w^Tx^{(i)} + b\right) \geq 1, \forall i<br>\]</p>
<p>同时，注意到在优化问题中，最优解必然会有部分约束起作用，也就是存在$i$使得$y^{(i)}\left(w^Tx^{(i)} + b\right) = 1$，因此我们有：<br>\[<br>\min_{i} \frac{y^{(i)}\left(w^Tx^{(i)}+b\right)}{\lVert w \rVert} = \frac{1}{\lVert w \rVert}<br>\]</p>
<p>因此，我们得到如下优化问题：<br>\[<br>\max_{w,b} \frac{1}{\lVert w \rVert} \\<br>\text{s.t. } y^{(i)}\left(w^Tx^{(i)} + b\right) \geq 1, \forall i<br>\]</p>
<p>最后，为了简化问题的求解，我们注意到$\max \frac{1}{\lVert w \rVert}$和$\min \lVert w \rVert^2$（也可以写成$\min w^Tw$）是等价的，因此可以把优化问题改写为：<br>\[<br>\min_{w,b} \frac{1}{2}w^Tw \\<br>\text{s.t. } y^{(i)}\left(w^Tx^{(i)} + b\right) \geq 1, \forall i<br>\]</p>
<p>其中$\frac{1}{2}$仅仅是表示二次目标函数时的一个通用约定，没有其他含义。到这里，我们就得到了<strong>线性可分情形下的支持向量机模型</strong>。这个模型是一个<strong>二次规划</strong>问题，可以用典型的凸优化方法求解。</p>
<p>最后，我们可以对“支持向量机”的名字做一个简单的解释。由于支持向量机是一个含约束的二次规划问题，那么其约束就必然有起作用和不起作用的分别。很明显，当约束起作用时，样本点离分离超平面的距离刚好等于$\frac{1}{\lVert w \rVert}$，而约束不起作用时，样本点离分离超平面的距离都超过这个值。因此，<strong>起作用约束对应的是离分离超平面最近的那些样本点</strong>。同时，在约束优化中，我们知道，删去不起作用的约束，不会影响问题的最优解。这就意味着，支持向量机的计算结果仅取决于起作用约束，也就是离分离超平面最近的点。这些点就是所谓的<strong>支持向量</strong>，因为它们“支撑”了超平面。支持向量机的名称也来源于此。</p>
<p>综上所述，<strong>那么支持向量机的思想在于，分类问题中，确定边界是最重要的，而边界的位置则取决于离边界最近的点。</strong></p>
<p>应该说，支持向量机是一个很优美的模型：一方面，依托于“最大间隔”，数学图景非常清晰。另一方面，凸优化是目前被研究最充分的优化问题，因此支持向量机具有简单的数学模型，也易于求解。</p>
<h2 id="1-2-一般情形"><a href="#1-2-一般情形" class="headerlink" title="1.2 一般情形"></a>1.2 一般情形</h2><p>在线性可分场景下构造的支持向量机有两个方面的问题：第一，在数据不可分的时候，模型没有可行解；第二，即使数据可分，由于支持向量机仅考虑支持向量，如果支持向量有坏数据，就会极大影响求解的结果。这两种情况本质是相同的，即<strong>线性可分支持向量机对于边界上的误差容忍度过低</strong>。</p>
<p>为此，只需把支持向量机的模型改成如下形式：<br>\begin{equation*}<br>\begin{aligned}<br>&amp;\min_{w,b} C\sum_{i=1}^N\xi_i+\frac{1}{2}w^Tw \\<br>\text{s.t. } &amp; y^{(i)}\left(w^Tx^{(i)} + b\right) \geq 1 - \xi_i, \forall i \\<br>&amp; \xi_i\geq 0, \forall i<br>\end{aligned}<br>\end{equation*}</p>
<p>这个模型中，$\xi_i$是第$i$个样本点违背约束的程度，如果$\xi_i=0$，则说明第$i$个样本点被成功分类，并且分离超平面有“足够”的距离，否则就认为样本点分类错误，并引入惩罚项。由此可见，一般的支持向量机模型允许样本点越过支持向量对应的点，但这些点会根据越界大小引入惩罚，而支持向量机模型会权衡惩罚项的大小和分类的间隔距离，做出最优的选择。其中，两者的权重由惩罚因子$C$决定，C越大，惩罚越大，分类结果就越接近线性可分支持向量机的分类结果。</p>
<h1 id="二、基于损失函数的构造"><a href="#二、基于损失函数的构造" class="headerlink" title="二、基于损失函数的构造"></a>二、基于损失函数的构造</h1><p>我们首先考虑支持向量机的求解目标。给定一个样本点$x^{(i)}$，如果$y^{(i)}=1$，则我们希望$w^Tx^{(i)}+b\geq 1$（注意这里不是0，因为支持向量机要求正确分类的样本点离超平面有一定距离），因此，如果这一目标实现了，损失函数则应该是0，而如果没实现，则损失函数应该大于0。如果$y^{(i)}=-1$，则应该有$w^Tx^{(i)}+b\leq -1$。</p>
<p>令$\hat{y}^{(i)}=w^Tx^{(i)}+b$，我们采用如下损失函数：<br>\[<br>L\left(y^{(i)},\hat{y}^{(i)}\right) = \left\{<br>\begin{split}<br>\max\{0, 1 - \hat{y}^{(i)}\}, &amp; \text{if } y^{(i)}=1 \\<br>\max\{0, \hat{y}^{(i)} + 1\}, &amp; \text{if } y^{(i)}=-1<br>\end{split}<br>\right.<br>\]</p>
<p>这个损失函数一般称为<strong>合页损失函数</strong>。</p>
<p>则分类问题转化为：<br>\[<br>\min_{w,b} \sum_{i=1}^NL\left(y^{(i)}, w^Tx^{(i)}+b\right)<br>\]</p>
<p>当然，为了避免过拟合，还需要加上正则化项，于是得到：<br>\[<br>\min_{w,b} \sum_{i=1}^NL\left(y^{(i)}, w^Tx^{(i)}+b\right) + \lambda w^Tw<br>\]</p>
<p>这就是<strong>支持向量机的损失函数构造</strong>。接下来，我们来证明这种构造和基于间隔的构造的等价性。我们引入辅助变量$\xi_i=L\left(y^{(i)}, w^Tx^{(i)}+b\right)$，把上述问题转化为：<br>\[<br>\min_{w,b} \sum_{i=1}^N\xi_i+ \lambda \lVert w \rVert^2 \\<br>\text{s.t. } L\left(y^{(i)}, w^Tx^{(i)}+b\right) = \xi_i<br>\]</p>
<p>显然该问题等价于：<br>\[<br>\min_{w,b} \sum_{i=1}^N\xi_i+ \lambda w^Ts \\<br>\text{s.t. } L\left(y^{(i)}, w^Tx^{(i)}+b\right) \leq \xi_i<br>\]</p>
<p>考察上述问题中的约束，当$y^{(i)}=1$时，该约束即为：<br>\[<br>\max\left\{0, 1 - \left(w^Tx^{(i)}+b\right)\right\} \leq \xi_i<br>\]</p>
<p>而两个数的最大值小于$\xi_i$，说明这两个数均小于$\xi_i$，因此上式等价于：<br>\[<br>\xi_i \geq 0 \\<br>w^Tx^{(i)}+b \geq 1 - \xi_i<br>\]</p>
<p>以上讨论了$y^{(i)} = 1$的情形，对于$y^{(i)}=-1$的情形，情况是类似的，但结果略有不同：<br>\[<br>\xi_i \geq 0 \\<br>w^Tx^{(i)}+b \leq \xi_i - 1<br>\]</p>
<p>这两种类型的约束可以合并为统一的形式：<br>\[<br>\xi_i \geq 0 \\<br>y^{(i)}\left(w^Tx^{(i)}+b\right) \geq 1 - \xi_i<br>\]</p>
<p>由此可得，支持向量机的模型等价于：<br>\[<br>\min_{w,b} \sum_{i=1}^N\xi_i+\lambda w^Tw \\<br>\text{s.t. } y^{(i)}\left(w^Tx^{(i)} + b\right) \geq 1 - \xi_i, \forall i \\<br>\xi_i\geq 0, \forall i<br>\]</p>
<p>最后，将目标函数除以$2\lambda$，不会改变结果，于是我们得到：<br>\[<br>\min_{w,b} \frac{1}{2\lambda}\sum_{i=1}^N\xi_i+\frac{1}{2}w^Tw \\<br>\text{s.t. } y^{(i)}\left(w^Tx^{(i)} + b\right) \geq 1 - \xi_i, \forall i \\<br>\xi_i\geq 0, \forall i<br>\]</p>
<p>很明显，该式与基于间隔的构造方法得出的模型是等价的，只需要令常数$C=\frac{1}{2\lambda}$即可。</p>
<p>作为总结，支持向量机是一种使分类间隔最大化的分类方法，同时也可以理解为目标函数为合页损失函数的学习方法。支持向量机的分类结果受到分类边界处的样本，即支持向量和误分类样本的影响。支持向量机的松弛项惩罚系数$C$对应于正则化参数$\lambda$，$C$越大，则正则化参数越小，模型对边界数据的误差和误分类样本就越敏感，而对误差敏感则意味着过拟合。反之，$C$越小，则模型的容忍度就越高，也越容易欠拟合。</p>
<p>值得注意的是，从损失函数的角度来看，支持向量机的损失函数并不比Logistic回归的损失函数更“优越”，因此没有明显的证据表明支持向量机比Logistic回归更好。<strong>但支持向量机的优势一方面在于所求解的问题是二次规划，也就是一类凸优化问题，从而可以很好地求解，另一方面则在于其很容易拓展到非线性情形，从而获得更强的表现力。</strong>关于后者，我们将在后续文章中论述。</p>
]]></content>
      
        <categories>
            
            <category> 机器学习 </category>
            
            <category> 模型 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 支持向量机 </tag>
            
            <tag> SVM </tag>
            
            <tag> 合页损失函数 </tag>
            
            <tag> 最大间隔 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[牛顿法]]></title>
      <url>/articles/optimization-newton.html</url>
      <content type="html"><![CDATA[<p>相较于梯度下降方法，牛顿法通常具有更快的收敛性，即二次收敛性。当然，牛顿法对于函数性质的要求更为苛刻：它要求函数是二阶连续可导的，而梯度方法只要求一阶可导（包括在收敛性证明中，也不需要用到二阶导数）。牛顿法的瓶颈在于二阶导数矩阵（即海森矩阵）的计算和求逆，因此，其通常应用在这些导数容易显式求得的情形下。<br><a id="more"></a></p>
<h1 id="一、牛顿法"><a href="#一、牛顿法" class="headerlink" title="一、牛顿法"></a>一、牛顿法</h1><p>牛顿法来源于二次函数的极小值求解。考虑$f(x)$在给定点$x$处的二阶泰勒展开：<br>\[<br>f(y) \approx f(x) + \left[\nabla f(x)\right]^T(y-x) + \frac{1}{2}(y-x)^T\left[\nabla^2 f(x)\right](y-x)<br>\]</p>
<p>如果这个式子严格成立，那么很容易求得$f(x)$的极小值点为：<br>\[<br>x^*=x - \left[\nabla^2 f(x)\right]^{-1}\nabla f(x)<br>\]</p>
<p>当然，实际的函数不一定是严格的二次函数，所以上式通常应该写成迭代的格式：<br>\[<br>x^+=x - \left[\nabla^2 f(x)\right]^{-1}\nabla f(x)<br>\]</p>
<p>牛顿法的一种推广形式为：<br>\[<br>x^+=x - \alpha \left[\nabla^2 f(x)\right]^{-1}\nabla f(x)<br>\]</p>
<p>其中$\alpha$为搜索步长，$\alpha=\arg\min_\alpha f(x^+)$。这种形式可以看成用原始的牛顿方法求得搜索方向，再沿着该方向进行一维搜索。我们把这种方法简称为<strong>阻尼牛顿法</strong>，而把前面所说的不进行一维搜索的方法称为<strong>原始牛顿法</strong>，以示区别。</p>
<h1 id="二、牛顿法的收敛性"><a href="#二、牛顿法的收敛性" class="headerlink" title="二、牛顿法的收敛性"></a>二、牛顿法的收敛性</h1><h2 id="2-1-需要增加的条件"><a href="#2-1-需要增加的条件" class="headerlink" title="2.1 需要增加的条件"></a>2.1 需要增加的条件</h2><p>这里我们只讨论原始的牛顿法，即$\alpha=1$的情形。和梯度下降法相同，我们假设$f(x)$具有$m$-强凸性，其二阶导数的最大特征值不超过$M$。同时，还要假设其二阶导数是$L-Lipschitz$连续的，即：<br>\[<br>\lVert \nabla^2 f(x) - \nabla^2 f(y) \rVert_2 \leq L \lVert x-y \rVert_2<br>\]</p>
<p>这个性质可以推出：<br>\begin{equation} \label{eq:lipschitz}<br>\left\lVert\nabla f(y) - \nabla f(x) - \left[ \nabla^2f(x) \right] (y-x) \right\rVert \leq \frac{1}{2}L \lVert x-y \rVert^2<br>\end{equation}</p>
<p>这个约束意味着函数与二次函数“相差”不大（对于二次函数来说$L$为0）。</p>
<h2 id="2-2-原始牛顿法的收敛性"><a href="#2-2-原始牛顿法的收敛性" class="headerlink" title="2.2 原始牛顿法的收敛性"></a>2.2 原始牛顿法的收敛性</h2><h3 id="2-2-1-自变量的收敛性"><a href="#2-2-1-自变量的收敛性" class="headerlink" title="2.2.1 自变量的收敛性"></a>2.2.1 自变量的收敛性</h3><p>首先，我们来验证自变量的收敛性。假设最优解为$x^*$，则显然$\nabla f(x^*)=0$，从而有：<br>\[<br>x^+-x^*=x-x^*-\left[\nabla^2f(x)\right]^{-1}\nabla f(x) \\<br>=\left[\nabla^2f(x)\right]^{-1}\left(\nabla f(x^*) - \nabla f(x) - \left[\nabla^2 f(x)\right] (x^*-x)\right)<br>\]</p>
<p>两边取2-范数，并考虑$\lVert Ax \rVert \leq \lVert A \rVert \lVert x \rVert$，可以得到：<br>\[<br>\lVert x^+-x^* \rVert \leq \left\lVert \left[\nabla^2f(x)\right]^{-1} \right\rVert \left\lVert \nabla f(x^*) - \nabla f(x) - \left[\nabla^2 f(x)\right] (x^*-x)\right\rVert<br>\]</p>
<p>再考虑到$\nabla^2 f(x)$的特征值在$m$和$M$之间，所以$\left[\nabla^2 f(x)\right]^{-1}$的特征值在$1/M$和$1/m$之间。同时考虑Lipschitz条件\eqref{eq:lipschitz}，可以得到：<br>\[<br>\lVert x^+-x^* \rVert \leq \frac{L}{2m}\lVert x - x^* \rVert^2<br>\]</p>
<p>我们对这个式子稍作变形：<br>\[<br>\frac{L}{2m}\lVert x^+-x^* \rVert \leq \left(\frac{L}{2m}\lVert x - x^* \rVert\right)^2<br>\]</p>
<p>由此可见，如果$x-x^*$足够小，使得$\frac{L}{2m}\lVert x - x^* \rVert &lt; 1$，那么经过一次迭代之后，误差会以平方的形式缩小。这就意味着：<strong>牛顿法在局部具有2级收敛性，在决策变量$x$接近最优解时，其趋近于最优解的速度非常快。</strong>举个例子，对于线性收敛来说，误差可能是$0.1,0.05,0.025,\dots$的速度减小，而对于2级收敛则为$0.1,0.01,0.0001,0.00000001$的速度。可见2级收敛的收敛速度比线性收敛快很多。当然，<strong>这是建立在决策变量已经接近最优解的情形，如果初始值离最优解较远，牛顿法的收敛性并不能保证</strong>。</p>
<h3 id="2-2-2-因变量的收敛性"><a href="#2-2-2-因变量的收敛性" class="headerlink" title="2.2.2 因变量的收敛性"></a>2.2.2 因变量的收敛性</h3><p>自变量的收敛速度是2级，因变量的收敛速度同样是2级。为此我们需要知道$f(x)-f(x^*)$和$x-x^*$的关系。事实上，由于$\nabla f(x)=0$，我们有<br>\[<br>\left| f(x) - f(x^*) \right| = \left| f(x) - f(x^*) - (x-x^*)^T\nabla f(x) \right|<br>\]</p>
<p>从而有<br>\[<br>\frac{m}{2} \lVert x - x^* \rVert^2 \leq \left| f(x) - f(x^*) \right| \leq \frac{M}{2} \lVert x - x^* \rVert^2<br>\]</p>
<p>对于$x^+$有类似的结论，于是我们可以得出：<br>\[<br>\left|f(x^+) - f(x^*) \right| \leq \frac{M}{2}\lVert x^+-x^* \rVert^2 \leq \frac{ML^2}{8m^2}\lVert x - x^* \rVert^4 \leq \frac{ML^2}{2m^4}\left| f(x) - f(x^*) \right|^2<br>\]</p>
<p>这就说明因变量同样遵循2级收敛性。</p>
]]></content>
      
        <categories>
            
            <category> 优化 </category>
            
            <category> 算法 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 优化 </tag>
            
            <tag> 二阶收敛 </tag>
            
            <tag> 牛顿法 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[梯度下降法及其收敛性]]></title>
      <url>/articles/optimization-gradient-descent.html</url>
      <content type="html"><![CDATA[<p>在高维的优化问题中，梯度下降法是一类常见的优化算法，它利用“梯度是函数上升最快的方向”这一特点，沿着梯度反方向搜索，以降低函数值。在一定条件下，梯度下降法可以达到线性收敛性，尽管和牛顿法等二阶收敛算法有差距，但其较少的假设条件和方便的计算使其成为一种广泛使用的方法。<br><a id="more"></a></p>
<h1 id="一、梯度下降法的基本概念"><a href="#一、梯度下降法的基本概念" class="headerlink" title="一、梯度下降法的基本概念"></a>一、梯度下降法的基本概念</h1><p>考虑如下优化问题：<br>\[<br>\min_x f(x)<br>\]</p>
<p>其中$x$是一个$n$维变量。假设我们已经目前处在一个初始位置$x_0$，我们希望得到一个新的位置$x_1$，使得$f(x_1) &lt; f(x_0)$。注意我们并不要求$x_1$就是这个优化问题的最小值，因为得到$x_1$之后，我们可以把$x_1$视作初始点，继续迭代，通过迭代次数的增加来逼近最优解。因此，更准确的问题描述是：经过$k$次迭代后，我们到达了$x_k$，现在要寻找$x_{k+1}$，使$f(x_{k+1})&lt;f(x_k)$。</p>
<p>那么这里涉及到两个的问题，一是$x_{k+1}$在$x_k$的什么方向上（即<strong>搜索方向</strong>），二是沿着这个方向，$x_{k+1}$和$x_k$的距离是多少（即<strong>搜索步长</strong>）。可以看出，当搜索方向固定后，搜索步长的问题就变成了一维搜索问题，可以用一系列方法来求解，例如可以用0.618法或牛顿法等直接求得该方向的最小值，或者沿该方向前进一定的步长，得到该方向上一个“较小”的函数值。所以，高维优化问题和一维优化问题的本质区别在于搜索方向的求解。</p>
<p>梯度下降法采用了一个直观的思路：在这个$n$维空间中，函数值下降最快的方向是什么？这里就会用到一个数学上的概念：沿着高维空间的梯度方向，函数值上升最快。因此，沿着<strong>梯度的反方向</strong>，函数值下降最快。当然，由于梯度是局部概念，在$x_k$点看过去，下降最快的方向不一定就是最优解所在方向，但这并不重要，因为我们并不要求一次性找到最优解，只要找到一个有“足够”下降的点$x_{k+1}$即可。</p>
<p>根据这样的想法，梯度下降法可以描述为：<br>\[<br>x_{k+1}=x_k-\alpha_{k}\nabla f(x_k)<br>\]</p>
<p>其中$\alpha_k$的大小决定了搜索步长。确定了梯度方向之后，搜索步长的确定通常有几种策略：</p>
<ol>
<li><p>沿着梯度方向，直接寻找该方向的最小值，即：<br>\[<br>\alpha_k=\arg\min_{\alpha}f\left[x_k-\alpha\nabla f(x_k)\right]<br>\]</p>
</li>
<li><p>用启发式方法找到该方向的“较小值”，最简单的是固定$\alpha_k=\alpha$</p>
</li>
</ol>
<h1 id="二、梯度下降法的收敛性"><a href="#二、梯度下降法的收敛性" class="headerlink" title="二、梯度下降法的收敛性"></a>二、梯度下降法的收敛性</h1><h2 id="2-1-强凸性"><a href="#2-1-强凸性" class="headerlink" title="2.1 强凸性"></a>2.1 强凸性</h2><p>我们以固定$\alpha$的方法为例，讨论梯度下降法的收敛性。这里需要说明的是，仅仅假设$f(x)$为凸函数，对于求解收敛速度并不够，我们需要更强的条件，也就是<strong>强凸性</strong>（strong-convexity)。具体来说，如果一个函数的二阶导数（高维情况下，应该是海森矩阵的所有特征值）均大于一个正数$m$，那么我们就把这个函数成为$m$-强凸的（m-strongly convex）。</p>
<p>在这里，我们需要利用的是强凸性的一个等价性质：<br>\[<br>f(x+\Delta x) \geq f(x) + \Delta x^T\nabla f(x) + \frac{1}{2}m \lVert \Delta x \rVert ^2<br>\]</p>
<p>可以看出，如果$m=0$，强凸性就会退化成凸性。实际上，凸性要求一个函数在局部增长得比线性函数要快，而强凸性则要求其增长得比一个二次函数（二次项系数为$m/2$）快。</p>
<p>这里我们做一个简单推导：固定$x$时，上面式子的右侧可以看作$\Delta x$的二次函数，可以证明，<br>\[<br>\Delta x^T\nabla f(x) + \frac{1}{2}m \lVert \Delta x \rVert ^2 \geq -\frac{1}{2m} \lVert \nabla f(x) \rVert ^2<br>\]</p>
<p>其中等号成立的条件是$\Delta x=-\frac{1}{m}\nabla f(x)$。由此我们得到：<br>\[<br>f(x+\Delta x) \geq f(x) -\frac{1}{2m} \lVert \nabla f(x) \rVert ^2<br>\]</p>
<p>同时，注意到该等式对任意$\Delta x$均成立，我们可以设置合适的$\Delta x$，使$x+\Delta x=x^*$，于是我们得到：<br>\[<br>p^*=f(x^*)\geq f(x) -\frac{1}{2m} \lVert \nabla f(x) \rVert ^2<br>\]</p>
<p>这个式子可以改写成如下表达式：<br>\begin{equation} \label{eq:m}<br>\lVert \nabla f(x) \rVert ^2 \geq 2m\left(f(x)-p^*\right)<br>\end{equation}</p>
<p>这个式子说明了强凸性对于函数的梯度值的影响。可以看出，强凸性让对函数的梯度值给出了限制，使得梯度不至于“太小”。直观来说，凸性越强，梯度值就越大，每一步走得就越远，因此收敛也会更快。当然，这只是一个直观的说明，具体的收敛速度还和另外一个因素有关，那就是<strong>条件数</strong>。</p>
<h2 id="2-2-最大特征值的影响"><a href="#2-2-最大特征值的影响" class="headerlink" title="2.2 最大特征值的影响"></a>2.2 最大特征值的影响</h2><p>直观来说，凸性越强（即$m$越大），梯度就越大。但我们应该注意到，这种梯度的“大小”并不能完全反映收敛的快慢，因为收敛的快慢还取决于另一个因素：函数离最优值的“距离”，而这个所谓的“距离”则是由函数的二阶导数（或海森矩阵特征值）的最大值衡量。具体来说我们有如下式子：<br>\[<br>f(x+\Delta x) \leq f(x) + \Delta x^T\nabla f(x) + \frac{1}{2}M \lVert \Delta x \rVert ^2<br>\]</p>
<p>结合强凸性条件，可以看出$m$和$M$确定了函数二阶导数的上限和下限。我们可以把梯度下降法公式代入上式，令$x^+=x-\alpha \nabla f(x)$则有：<br>\[<br>f(x^+) \leq f(x) + \left(-\alpha+\frac{M\alpha^2}{2}\right) \lVert \nabla f(x) \rVert ^2<br>\]</p>
<p>两边同时减去最优值$p^*$，则有：<br>\[<br>f(x^+) - p^* \leq f(x) - p^* + \left(-\alpha+\frac{M\alpha^2}{2}\right) \lVert \nabla f(x) \rVert ^2<br>\]</p>
<p>由于$f(x)-p^*$反映了函数值离最优解的距离，可见如果要让$f(x^*)$离最优解更近，则需要保证$\left(-\alpha+M\alpha^2/2\right)&lt;0$。注意到这是$\alpha$的二次函数，如果M已知的话，我们可以选择$\alpha=1/M$，此时有<br>\begin{equation} \label{eq:M}<br>f(x^+) - p^* \leq f(x) - p^* - \frac{1}{2M}\lVert \nabla f(x) \rVert ^2<br>\end{equation}</p>
<p>由这个式子可以看出，如果$M$较大，则函数值在迭代过程中下降也较慢。可见$M$和$m$如果同时增大，其作用可能会相互抵消。更进一步的分析表明，它们的比例才是决定性的因素。</p>
<h2 id="2-3-条件数"><a href="#2-3-条件数" class="headerlink" title="2.3 条件数"></a>2.3 条件数</h2><p>把不等式\eqref{eq:m}代入不等式\eqref{eq:M}，我们可以得到：<br>\[<br>f(x^+)-p^*\leq \left(1-\frac{m}{M}\right)\left(f(x)-p^*\right)<br>\]</p>
<p>至此，我们得到了梯度下降法的收敛性。由于$1-m/M&lt;1$，可以看出在迭代过程中函数值不断接近最优解，而每次迭代，函数值和最优解的距离都线性减小。因此，梯度下降法具有<strong>线性收敛性</strong>。</p>
<p>同时，也可以看出，收敛性的好坏取决于$m$和$M$的相对大小。我们把$M/m$成为$f(x)$的<strong>条件数</strong>，于是条件数越大的函数，其收敛效果就越差。</p>
<h1 id="三、讨论"><a href="#三、讨论" class="headerlink" title="三、讨论"></a>三、讨论</h1><p>在上述证明中，我们假设了$m$和$M$都是已知的。这一点在实际的函数中并不容易做到。一个严重的问题是，如果$M$未知，那么就无法根据$M$的值设置迭代步长$\alpha$，而不合适的迭代步长甚至会导致函数发散！针对这样的问题，一般需要设置变步长搜索，而最简单的则是沿着梯度方向进行一维搜索，直接找该方向的最小值。这种方法相对来说比较耗时，还有一些其他的方法，此处不再赘述。</p>
<p>我们曾经说明过，对于非凸的函数，即使局部最优解的寻找（甚至判定）也是极其困难的。这里我们针对凸函数证明了，凸性的好坏会影响算法的收敛速度。如果梯度下降法在凸性“较差”的函数收敛速度慢，那么可以直观地想象（只是想象，并不是证明），梯度下降法在非凸函数中会遇到更多的问题。</p>
<p>事实上，非凸函数中的问题不仅仅是收敛速度问题，梯度下降法的收敛判据本身也存在问题。这是因为梯度下降法以梯度为0作为收敛判据，但在非凸问题中，梯度为0的点可能是极小值点，也可能是极大值点和<strong>鞍点</strong>。在高维问题中，鞍点的数量远大于极小值点的数量，因此梯度下降法很大程度上只能收敛到鞍点。鞍点是在一个方向上为极小值，而在另一个方向上为极大值的点，鞍点不是极小值点，也存在理论上的下降方向，但鞍点附近非常平坦，极易触发收敛判据。这就是著名的<strong>鞍点问题</strong>，遗憾的是鞍点问题并没有特别好的解决方法。</p>
<p>然而，梯度下降法存在的这些问题，在几乎所有别的优化方法中同样存在。因此，即便在非凸优化中，梯度下降法也是目前能找到的最好的方法了。目前，仍然有大量的研究论述梯度下降法在各种条件下的收敛性，可见这一方法的重要性和本质困难。</p>
]]></content>
      
        <categories>
            
            <category> 优化 </category>
            
            <category> 算法 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 梯度 </tag>
            
            <tag> 收敛 </tag>
            
            <tag> 导数 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[一维搜索：0.618法与牛顿法]]></title>
      <url>/articles/optimization-line-search.html</url>
      <content type="html"><![CDATA[<p>对于一般的优化问题，常见的解法是根据某个初始位置，确定一个搜索方向，把搜索问题暂时看作沿该方向的一维优化问题，再确定前进的步长。由此可见，一维的优化问题是最简单、也是最基本的优化问题。0.618法和牛顿法是两种具有代表性的方法。前者采用逐次试探的方式，不断逼近最优解，后者则把函数近似为二次函数，采用二次函数求极值的方法进行迭代求解。<br><a id="more"></a></p>
<h1 id="一、0-618法"><a href="#一、0-618法" class="headerlink" title="一、0.618法"></a>一、0.618法</h1><p>0.618法是<strong>试探法</strong>的一种。考虑如下一维搜索问题：<br>\[<br>\min_x f(x)<br>\]</p>
<p>其中x是一维变量。我们此处仅讨论局部最优解的求解，因此不妨假设$f(x)$在某个局部$[a,b]$内是凸的。同时，可以假设$f(a)\leq f(b)$，并假设极小值点$x_0\in [a,b]$（这两个假设是为了简化论述，在实际算法中并不必要）。于是我们有$a\leq x_0 \leq b$，$f(x_0)\leq f(a) \leq f(b)$。</p>
<p>由于$x_0$未知，为了缩小区间，我们在$[a,b]$中取两个点$x_1,x_2$（$x_1&lt;x_2$），并计算$f(x_1)$和$f(x_2)$。此时可能出现两种情况：</p>
<ol>
<li>$f(x_1) \leq f(x_2)$，那么根据凸性必有$f(x_1)\leq f(x_2) \leq f(b)$，因此$(x_2,b]$内的所有点都不小于$f(x_2)$，因此可以被删去。而$[a,x_1]$和$[x_1,x_2]$中的点仍有可能是极值点。</li>
<li>$f(x_1) \geq f(x_2)$，同理，可以删去$[a,x_1]$。<br>因此，根据两个端点$a,b$的函数值和两个中间点$x_1,x_2$的值，就可以将搜索区间从$[a,b]$缩小到$[a,x_2]$或$[x_1,b]$，这就是<strong>试探法</strong>的基本思路。</li>
</ol>
<p>那么，$x_1$和$x_2$应该如何选取呢？一种方法是尽量让区间缩小得更多。此时可以将$x_1$和$x_2$尽量靠近中点，这样可以保证每次都删去将近一半的区间。但一般来说，我们并不会采取这种方式。</p>
<p>更常见的思路是：每次操作时都需要计算$f(x_1)$和$f(x_2)$，而这个计算有可能非常耗时。那么，有没有可能在下一次迭代中，继续用到上一次的计算结果，从而减少计算量呢？例如，第一次迭代中选取了$[a,b$区间中的$x_1,x_2$，计算发现$f(x_1) \leq f(x_2)$，从而可以删去$(x_2,b]$，保留$[a,x_2]$。注意到$x_1\in [a,x_2]$，因此在下一次迭代，选取两个中间点时，是否可以把$x_1$当做其中一个中间点？这样，就可以减少一半的计算量。</p>
<p>如果采用这个思路，一个直接的问题是：能否保证每次迭代后区间长度都能稳定地减少？下面我们来分析这个问题。</p>
<p>不妨假设所选区间为$[0,1]$，在选取中间点时，为了保证在两种情况下删除的区间大小一致，我们可以选择$x$和$1-x$作为中间点。假设$1-x<x$，即$x>0.5$，这样删去的区间大小即为$1-x$。</x$，即$x></p>
<p>如果删去的是$(x,1]$，则留下了$[0,x]$，且$1-x\in [0, x]$。此时，删去的区间的长度是原区间的$1-x$倍。在选取中间点的时候，我们希望$1-x$是其中一个中间点，这就意味着如果$f(1-x)$大于另一个中间点的函数值，则删去的区间应为现在区间$[0,x]$的$1-x$倍，即$x(1-x)$。因此，有两种可能：</p>
<ol>
<li>$1-x$为靠左的中间点，则$1-x=x(1-x)$，得出$x=1$，不符合$x$是中间点的要求；</li>
<li>$1-x$为靠右的中间点，则$x-(1-x) = x(1-x)$,得到$x^2+x-1=0$，得到$x=\frac{\sqrt{5}-1}{2}\approx 0.618$。</li>
</ol>
<p>由此可见，如果要保证每次删去的区间长度与原区间长度的比值一致，同时要求前一次迭代所求的中间点在后一次中能用上，中间点应该选在区间长度的0.618倍。此时，每次迭代，区间长度都会缩小为原区间长度的0.618倍。这种收敛方式我们一般称为<strong>线性收敛</strong>，因为每次迭代后最优解的范围与前一次迭代的最优解范围呈线性关系（0.618倍）。除了线性收敛，还有些算法的收敛速度更快，牛顿法就是其中一种，可以达到<strong>二级收敛</strong>。</p>
<h1 id="二、牛顿法"><a href="#二、牛顿法" class="headerlink" title="二、牛顿法"></a>二、牛顿法</h1>]]></content>
      
        <categories>
            
            <category> 优化 </category>
            
            <category> 算法 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 优选法 </tag>
            
            <tag> 0.618 </tag>
            
            <tag> 黄金分割 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[对偶理论]]></title>
      <url>/articles/optimization-dual.html</url>
      <content type="html"><![CDATA[<p>对偶理论是优化理论中非常优美的部分，很多优化问题的求解都依赖对偶形式。强对偶定理保证了这种求解方法的正确性。</p>
<a id="more"></a>
<h1 id="一、拉格朗日函数和对偶问题"><a href="#一、拉格朗日函数和对偶问题" class="headerlink" title="一、拉格朗日函数和对偶问题"></a>一、拉格朗日函数和对偶问题</h1><p>考虑如下问题：<br>\[<br>p^*=\min f(x) \\<br>\text{s.t. } g(x) \leq 0, h(x)=0<br>\]</p>
<p>其拉格朗日函数为：<br>\[<br>L(x,\lambda, \mu)=f(x) + \lambda^Tg(x) + \mu^Th(x)<br>\]</p>
<p>此时可以证明：<br>\[<br>\max_{\lambda\geq 0,\mu} L(x, \lambda, \mu) = \left\{<br>\begin{split}<br>f(x),&amp;\text{if }g(x)\leq 0,h(x)=0 \\<br>+\infty,&amp;\text{otherwise}<br>\end{split}<br>\right.<br>\]</p>
<p>我们可以把原问题用拉格朗日函数表示：<br>\[<br>p^*=\min_x \max_{\lambda\geq 0,\mu} L(x,\lambda, \mu)<br>\]</p>
<p>此时不必再显式考虑约束，这是因为约束不满足的时候，$L$的最大值是$+\infty$，因此不可能成为最优解。</p>
<p>所谓<strong>对偶问题</strong>，实际上是把原问题的min和max调换顺序：<br>\[<br>d^*=\max_{\lambda\geq 0, \mu} \min_x L(x, \lambda, \mu)<br>\]</p>
<p>如果我们令$\theta(\lambda, \mu) = \min_x L(x, \lambda, \mu)$, 则对偶问题可以写成：<br>\[<br>d^*=\max_{\lambda\geq 0, \mu} \theta(\lambda, \mu)<br>\]</p>
<h1 id="二、对偶问题的例子：线性规划"><a href="#二、对偶问题的例子：线性规划" class="headerlink" title="二、对偶问题的例子：线性规划"></a>二、对偶问题的例子：线性规划</h1><p>上述对偶问题的定义比较一般化，实际上，在具体问题中，对偶问题的形式可能会非常简单。我们以线性规划为例说明。</p>
<p>考虑如下线性规划问题：<br>\[<br>p^*\min c^Tx \\<br>\text{s.t. } Ax\geq b<br>\]</p>
<p>其拉格朗日函数为：<br>\[<br>L(x, \lambda, \mu) = c^Tx-\lambda^T(Ax-b) = (c-A^T\lambda)^Tx+\lambda^Tb<br>\]</p>
<p>我们来计算$\theta(\lambda)$，显然有：<br>\[<br>\theta(\lambda) = \left\{<br>\begin{split}<br>\lambda^Tb,&amp;\text{if }c-A^T\lambda=0 \\<br>-\infty,&amp;\text{otherwise}<br>\end{split}<br>\right.<br>\]</p>
<p>由于对偶问题可以表述为$d^*=\max_{\lambda\geq 0} \theta(\lambda)$，所以只有满足约束$c-A^T\lambda=0$的$\lambda$才可能作为候选解。因此，对偶问题可以表述为如下形式：<br>\[<br>d^*=\max_\lambda \lambda^Tb \\<br>\text{s.t. } \lambda\geq 0, c-A^T\lambda=0<br>\]</p>
<p>由此可见，线性规划的对偶问题仍为线性规划。实际上，关于线性规划对偶问题的表述，有一套完整的规则，在任何一本线性规划的教材中均有提及，这里就不再赘述。</p>
<h1 id="三、弱对偶定理"><a href="#三、弱对偶定理" class="headerlink" title="三、弱对偶定理"></a>三、弱对偶定理</h1><p>弱对偶定理对于所有的优化问题均成立，该定理的表述非常简单：<br>\[<br>d^*\leq p^*<br>\]</p>
<p>或者说：<br>\[<br>\max_{\lambda\geq 0,\mu} \min_x L(x, \lambda, \mu) \leq \min_x \max_{\lambda\geq 0, \mu} L(x, \lambda, \mu)<br>\]</p>
<p>也就是说，一个最小化问题的对偶问题的最优解，永远小于该最小化问题的最优解。</p>
<p>证明并不困难，注意到下列事实：<br>\[<br>\min_xL(x,\lambda,\mu) \leq L(x, \lambda, \mu)<br>\]</p>
<p>两边同时对$\lambda$和$\mu$取最大值：<br>\[<br>d^*=\max_{\lambda\geq 0, \mu} \min_xL(x, \lambda, \mu) \leq \max_{\lambda\geq 0, \mu} L(x, \lambda, \mu)<br>\]</p>
<p>由于左边已经是常数$d^*$，左侧恒不大于右侧，自然不大于右侧的最小值，也就是$p^*$，我们就得到了弱对偶定理。</p>
<h1 id="四、强对偶定理"><a href="#四、强对偶定理" class="headerlink" title="四、强对偶定理"></a>四、强对偶定理</h1><p>弱对偶定理在任何条件下都成立，但一般情况下，我们不能保证$d^*=p^*$。两者之间的距离$p^*-d^*$被称为对偶间隙。一个很自然的问题是，对偶间隙是否有可能为0？或者说，原问题和对偶问题的最优解有可能相等吗？这个问题非常重要，因为如果对偶间隙为零，我们就可以用对偶问题的最优解来代替原问题的最优解。有的时候，对偶问题比原问题更好求解。更重要地，在非线性优化中，我们常常需要终止条件，如果我们能同时求解原问题和对偶问题，当两者的解的间隙足够小，我们就可以认为最优解已经（近似）达到，从而终止算法。</p>
]]></content>
      
        <categories>
            
            <category> 优化 </category>
            
            <category> 理论 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 对偶 </tag>
            
            <tag> 互补松弛 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[最优性条件：KKT]]></title>
      <url>/articles/optimization-kkt.html</url>
      <content type="html"><![CDATA[<p>在最优性判别中，基于导数的方法是一种相当有效的方法。对于无约束优化，可以直接利用一阶导数作为必要性判据，利用二阶导数作为充分性判据。这种方法可以推广到约束优化中，也就是著名的KKT条件。</p>
<a id="more"></a>
<h1 id="一、无约束优化的判据"><a href="#一、无约束优化的判据" class="headerlink" title="一、无约束优化的判据"></a>一、无约束优化的判据</h1><p>考虑一维的无约束优化问题$\min_x f(x)$，如果我们假设$f(x)$一阶可导，那么$x^*$为局部最优解的<strong>必要条件</strong>是一阶导数$f’(x^*)=0$。如果$f(x)$二阶可导，那么我们可以有<strong>充分条件</strong>$f’(x^*)=0,f’’(x^*)&gt;0$。对于凸问题，$f’’(x)\geq 0$恒成立，则$f’(x^*)=0$是$x^*$为(全局)最优解的<strong>充要条件</strong>。但对于一般的非凸问题，并没有比较好用的充要条件。</p>
<p>上述结论当然可以推广到高维的情况。考虑高维无约束优化问题$\min_x f(x)$，我们有：</p>
<ol>
<li>$x^*$为局部最优解的必要条件是$\nabla f(x)=0$</li>
<li>$x^*$为局部最优解的充分条件是$\nabla f(x)=0$且$\nabla^2 f(x)$正定</li>
<li>如果$f(x)$为凸函数，则$x^*$为全局最优解的充要条件为$\nabla f(x)=0$</li>
</ol>
<p>上述结论在一般的微积分课本中都有介绍，下面我们考虑如何把这些结论推广到约束优化中。实际上，我们只需要考虑第1种情况，因为后面两种情况是类似的。</p>
<h1 id="二、拉格朗日函数"><a href="#二、拉格朗日函数" class="headerlink" title="二、拉格朗日函数"></a>二、拉格朗日函数</h1><p>考虑下述约束优化问题：<br>\[<br>\min_x f(x) \\<br>\text{s.t. } g(x)\leq 0, h(x)=0<br>\]</p>
<p>为了将其转化为无约束优化问题，我们可以利用所谓的<strong>拉格朗日函数</strong>：<br>\[<br>L(x,\lambda,\mu) = f(x) + \lambda^T g(x) + \mu^T h(x)<br>\]</p>
<p>其中$\lambda\geq 0$。固定$x$，容易发现：<br>\[<br>\max_{\lambda\geq 0, \mu} L(x, \lambda, \mu) = \left\{<br>\begin{split}<br>f(x), &amp;\text{if } g(x)\leq 0, h(x)=0\\<br>+\infty, &amp;\text{otherwise}<br>\end{split}<br>\right.<br>\]</p>
<p>这是因为，如果$g(x)&gt;0$，则可以选择很大的$\lambda$，使$L$趋于正无穷。而如果$h(x)\neq 0$，则可以根据$h(x)$的符号，将$\mu$置为相同符号的大数，使$L$趋于正无穷。</p>
<p>由此可见，原来的约束优化问题可以等价表达为：<br>\[<br>\min_x \max_{\lambda\geq 0, \mu} L(x, \lambda, \mu)<br>\]</p>
<p>此时不再含有对$x$的约束$g(x)\leq 0, h(x)=0$，因为这些约束不满足的时候，必有$\max_{\lambda\geq 0, \mu} L=+\infty$，从而不可能成为最小值。然而，转化后的这个问题是一个$\min \max$类型的问题，而且第二层的$\max$中仍然要考虑$\lambda\geq 0$的约束。下面，我们来处理这个问题。</p>
<h1 id="三、KKT条件"><a href="#三、KKT条件" class="headerlink" title="三、KKT条件"></a>三、KKT条件</h1><p>引入了拉格朗日函数后，我们把优化问题的最优解记为$(x^*,\lambda^*,\mu^*)$，即：<br>\[<br>L(x^*,\lambda^*,\mu^*) = \min_x \max_{\lambda\geq 0, \mu} L(x, \lambda, \mu)<br>\]</p>
<h2 id="3-1-互补松弛"><a href="#3-1-互补松弛" class="headerlink" title="3.1 互补松弛"></a>3.1 互补松弛</h2><p>在最优解中，由于$h(x)=0$，因此$(\mu^*)^Th(x^*)=0$，这是显然的。此外，注意到$g(x)\leq 0, \lambda\geq 0$，那么$(\lambda^*)^Tg(x)$是否有其他约束呢？事实上我们有：<br>\[<br>(\lambda^*)^Tg(x) = 0<br>\]</p>
<p>换句话说，$\lambda^*$和$g(x^*)$中至少有一个为0。也可以解释为，如果$g(x^*)&lt;0$，则$\lambda^*=0$。这个结果可以从拉格朗日函数$L$的定义直接得出。这个条件通常称为互补松弛条件。</p>
<h2 id="3-2-导数条件"><a href="#3-2-导数条件" class="headerlink" title="3.2 导数条件"></a>3.2 导数条件</h2><p>为了获得和无约束优化类似的“一阶导数为0”的条件，我们需要一些<strong>正则化条件</strong>，其中最常见的条件是<strong>强对偶定理</strong>：<br>\[<br>L(x^*,\lambda^*,\mu^*) = \min_x \max_{\lambda\geq 0, \mu} L(x, \lambda, \mu) = \max_{\lambda\geq 0, \mu} \min_x L(x, \lambda, \mu)<br>\]</p>
<p>即原问题和对偶问题的最优解重合。此时我们可以考虑上面连等式的第1项和第3项，并在第3项的上层优化中固定$\lambda=\lambda^*,\mu=\mu^*$，这样就只需要考虑下层优化，即：<br>\[<br>L(x^*,\lambda^*,\mu^*) = \min_x L(x, \lambda^*, \mu^*)<br>\]</p>
<p>这已经是一个无约束优化问题了，我们可以直接写出其最优性必要条件：<br>\[<br>\nabla_xL(x^*,\lambda^*,\mu^*) = 0<br>\]</p>
<p>这就是一阶导数条件在约束优化中的推广，根据$L$的定义，我们可以将其展开为：<br>\[<br>\nabla f(x^*) + \left(\lambda^*\right)^T\nabla g(x^*) + \left(\mu^*\right)^T \nabla h(x^*) = 0 \\<br>\]</p>
<h2 id="3-3-KKT条件"><a href="#3-3-KKT条件" class="headerlink" title="3.3 KKT条件"></a>3.3 KKT条件</h2><p>综上所述，在一些正则化条件（如强对偶条件）下，约束优化的必要条件为：<br>\[<br>\nabla f(x^*) + \left(\lambda^*\right)^T\nabla g(x^*) + \left(\mu^*\right)^T \nabla h(x^*) = 0 \\<br>\lambda^* \geq 0 \\<br>g(x^*) \leq 0 \\<br>h(x^*) = 0 \\<br>\left(\lambda^*\right)^T g(x^*) = 0<br>\]</p>
<p>该式把约束优化问题转化为一组等式和不等式，对于简单的问题可以直接求解，对于复杂的问题，则为基于导数的优化方法提供了支撑。</p>
<p>同样地，KKT条件也有充分条件的版本，此时只需添加$\nabla^2_xL(x^*,\lambda^*,\mu^*)$正定的条件即可。对于凸优化来说，由于海森矩阵能保证半正定，所以上述必要条件成为充分条件。</p>
]]></content>
      
        <categories>
            
            <category> 优化 </category>
            
            <category> 理论 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 导数 </tag>
            
            <tag> 约束 </tag>
            
            <tag> KKT条件 </tag>
            
            <tag> 极值 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[凸性对于优化问题的意义]]></title>
      <url>/articles/optimization-convex.html</url>
      <content type="html"><![CDATA[<p>在优化问题中，凸优化问题很重要的一类子问题。一般来说，凸优化问题的求解无论在理论上，还是在算法上，都比非凸优化问题要成熟很多。可以证明，凸优化问题的局部最优即为全局最优，这使得凸优化问题的全局最优解的寻找更为简单。但凸性的意义不止于此。一个有意思的结论是：一般的非凸问题不仅全局最优难以求解，甚至局部最优的求解也非常困难！这篇文章会简要介绍相关的结论。<br><a id="more"></a></p>
<h1 id="一、凸性的基本定义"><a href="#一、凸性的基本定义" class="headerlink" title="一、凸性的基本定义"></a>一、凸性的基本定义</h1><p>优化问题的基本形式为：<br>\[<br>\min_x f(x) \\<br>\text{s.t. } g(x)\leq 0<br>\]</p>
<p>以$f(x)$为例，我们可以按如下方式定义凸性：任取定义域中的两个点$x_1$和$x_2$，计算它们的函数值$f(x_1)$和$f(x_2)$，并计算它们的中点的函数值$f(\frac{x_1+x_2}{2})$，如果中点的函数值不大于两个端点的函数值的均值，即：<br>\[<br>f\left(\frac{x_1+x_2}{2}\right) \leq \frac{f(x_1)+f(x_2)}{2}<br>\]<br>我们就称$f(x)$为凸函数。凸函数的图像是一个向下凸出的图像。</p>
<p>如果$f(x)$和$g(x)$都是凸函数，那么这个优化问题就称为凸优化问题。</p>
<p>当然，对于$g(x)$，我们还有另一种更一般化的定义方式。观察$g(x)\leq 0$的图像，可以发现，如果任意两个点$x_1$和$x_2$在这个集合内，那么它们的中点同样在这个集合内部。满足这种性质的集合，我们称为凸集。事实上，凸优化问题可以定义为：约束为凸集，目标函数为凸函数的最小化问题。这个定义比前面的定义会更加广泛一些，因为有的时候，约束并不能写成$g(x)\leq 0$的形式。</p>
<h1 id="二、凸优化问题的性质"><a href="#二、凸优化问题的性质" class="headerlink" title="二、凸优化问题的性质"></a>二、凸优化问题的性质</h1><h2 id="2-1-局部最优和全局最优"><a href="#2-1-局部最优和全局最优" class="headerlink" title="2.1 局部最优和全局最优"></a>2.1 局部最优和全局最优</h2><p>这里首先需要说明局部最优和全局最优的概念。</p>
<p>全局最优的概念很简单，如果有一个$x_0$满足约束，并且在约束成立的范围内，没有其他$x$，使$f(x)&lt;f(x_0)$，就把$x_0$称为全局最优。简单来说，全局最优就是在约束满足的范围内的最小值。<br>局部最优的要求松一些，如果有一个$x_0$满足约束，并且在$x_0$附近（严格的说是<strong>邻域</strong>），没有其他满足约束的$x$，使$f(x)&lt;f(x_0)$，就把$x_0$称为局部最优。简单来说，局部最优只需要保证在该点附近（可能范围很小）保证最优即可。</p>
<p>由此可见，为了确保局部最优，只需要在一个点的附近检查即可。如果目标函数满足一些可微性条件，这个“局部”甚至可以用该点的微分性质来判定。很容易想象，全局最优的判断要复杂很多，因为需要检查所有可能的解。但这里我想说的是，无论是局部最优还是全局最优，判定都不是一件简单的事情。当然，我所指的判定是<strong>充要条件</strong>。</p>
<h2 id="2-2-局部最优和全局最优的关系"><a href="#2-2-局部最优和全局最优的关系" class="headerlink" title="2.2 局部最优和全局最优的关系"></a>2.2 局部最优和全局最优的关系</h2><p>对于全局最优的求解，并没有一个一般的方法，因为所有的分析学工具都是针对“局部”，或者说，微分性质的。一种比较直观的思路是：是否有一种优化问题，其局部最优就是全局最优？这个问题的答案是肯定的，凸优化就是其中的一种。</p>
<p>我们这里不做严格证明，但可以简单论述一下。如果凸优化的局部最优不是全局最优，我们可以把该局部最优和全局最优连线。首先，由于约束是凸集，这条线必然在可行集内部。然后，从这个局部最优点看过去，这条线应该是“往下”的，因为全局最优解在它的“下方”（或者说，斜下方）。这就出现了矛盾：在局部最优的附近，所有的函数点都在它的“上方”，如果有函数值在下方，这个点也就不是局部最优解了！因此，凸优化的局部最优解也就是全局最优解。</p>
<h1 id="三、非凸问题的NP性质"><a href="#三、非凸问题的NP性质" class="headerlink" title="三、非凸问题的NP性质"></a>三、非凸问题的NP性质</h1><p>我们已经知道，凸优化问题在某种程度上是“简单”的。一个很自然的问题是，非凸优化问题是不是真的“难”？或者说，是不是还有别的方式来找到非凸优化问题的局部最优解和全局最优解？当然，有可能有部分非凸优化问题可以在比较短的时间内求解，但我们关心的是一般的非凸问题。<br>当然，所谓“简单”和“难”都是相对的，我们这里可以说明，部分非凸问题的全局最优解、局部最优解的求解都是所谓的<strong>NP完全问题</strong>。至少到目前为止，NP完全问题在求解上还存在着极大的困难，因此，在NP完全问题被攻克前，我们不能奢求对于<strong>一般</strong>的非凸问题求解全局最优解，甚至求解局部最优解也是不可行的。</p>
<h2 id="3-1-非凸问题的全局最优解"><a href="#3-1-非凸问题的全局最优解" class="headerlink" title="3.1 非凸问题的全局最优解"></a>3.1 非凸问题的全局最优解</h2><p>为了论述全局最优解的NP完全性，我们需要找一个已知的NP完全问题，并证明全局最优解的求解难度和这个已知问题相同。我们寻找的NP完全问题是<strong>部分和问题</strong>：给定一个数组和一个数字，该数组是否存在子数组，其和等于该数字？用数学语言叙述则为：给定数字$d_0$和一个数组$d_1,d_2,\dots,d_n$，问：是否存在$y_j\in{0,1},j=1,2,\dots,n$使得：<br>\[<br>\sum_{j=1}^nd_jy_j=d_0<br>\]</p>
<p>我们把上述问题称为<strong>问题1</strong>。同时，我们考虑如下问题(<strong>问题2</strong>)：<br>\[<br>\min \left(\sum_{j=1}^nd_jy_j-d_0\right)^2+\sum_{j=1}^ny_j(1-y_j) \\<br>\text{s.t. } 0 \leq y_j \leq 1, j=1,2,\dots, n<br>\]<br>注意，在第一个问题中，我们假设了$y_j$是整数，而第二个问题中，我们并没有假设$y_j$是整数。不难看出，问题2的目标函数始终是不小于0的。当问题1有解的时候，把该解代入问题2，就可以得到目标函数的最小值0。反过来，当问题2的目标函数最小值为0时，$y_j$只能都取0或1（否则第二项大于0，第一项不小于0，目标函数不可能等于0），这个解也满足问题1。</p>
<p>因此我们得出结论，问题1有解和问题2全局最优解为0是等价的。由于问题1是NP完全问题，问题2的全局最优解的求解也只能是NP完全问题。</p>
<p>这里要注意，我们并没有求解问题2的全局最优解，而是验证全局最优解是否为0。如果这种验证都被证明是一件“困难”的事，那么全局最优解的求解只会更加困难。</p>
<h2 id="3-2-含约束非凸问题的局部最优解"><a href="#3-2-含约束非凸问题的局部最优解" class="headerlink" title="3.2 含约束非凸问题的局部最优解"></a>3.2 含约束非凸问题的局部最优解</h2><p>这里我们考虑如下问题（<strong>问题3</strong>）：<br>\[<br>\min Q(x) = x^TDx, x\geq 0<br>\]<br>其中$D$是$n$阶矩阵，其元素均为整数。</p>
<p>Murty证明了如下定理：验证0是否为问题3的局部最优解，是一个NP完全问题！这个定理非常有意思，我们将在另一篇博客中论述。但同样的，如果局部最优解的判定已经是NP完全问题，那么局部最优解的求解只可能更加困难。</p>
<h2 id="3-3-无约束非凸问题的局部最优解"><a href="#3-3-无约束非凸问题的局部最优解" class="headerlink" title="3.3 无约束非凸问题的局部最优解"></a>3.3 无约束非凸问题的局部最优解</h2><p>3.2的条件中含有约束$x\geq 0$，也就是说，对于一般的含约束的非凸问题，没有有效的方法验证局部最优解。实际上，只要稍作修改，就可以发现，一般的无约束非凸问题也没有有效的方法验证局部最优解。我们只需要令$x=u^2$，则问题3转化为：<br>\[<br>\min Q(x) = [u^2]^TD[u^2]<br>\]<br>此时，对于u就是无约束优化问题了。显然，这个问题和问题3是等价的，它也是NP完全问题。</p>
]]></content>
      
        <categories>
            
            <category> 优化 </category>
            
            <category> 理论 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 优化 </tag>
            
            <tag> 凸优化 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[优化模型（一）：优化的要素]]></title>
      <url>/articles/optimization-config.html</url>
      <content type="html"><![CDATA[<p>在工程学科中，大量的问题均可以转化为优化问题。从字面意义上，优化即为在允许的范围(约束)内调整决策变量，使某个目标达到最大或最小。然而，在数学上处理优化之前，很自然的问题是：优化问题应该如何用数学语言表达？它有那些要素需要注意？这篇博客简要介绍优化问题的决策变量、目标函数和约束，这也是优化问题最基础的知识。</p>
<a id="more"></a>
<h1 id="一、最简单的优化问题"><a href="#一、最简单的优化问题" class="headerlink" title="一、最简单的优化问题"></a>一、最简单的优化问题</h1><p>最简单的优化问题在中学课本中就已经出现，例如初中学二次函数时，必然会讨论其极值问题，这是最简单的无约束优化问题。而下面的例子来源于高中课本，可以算最简单的约束优化问题：</p>
<blockquote>
<p>（摘自人教版高中数学必修5）某工厂用A、B两种配件生产甲乙两种产品，每生产一件甲产品使用4个A配件，耗时1h；每生产一件乙产品使用4个B配件，耗时2h。该厂每天最多可从配件厂获得16个A配件和12个B配件，每天工作8h。生产一件甲产品获利2万元，生产一件乙产品获利3万元，应该如何安排生产，使得总收益最大？</p>
</blockquote>
<p>这个问题虽然简单，但已经具备了一个优化问题的必备条件。首先是<strong>决策变量</strong>，也就是我们可以调整的变量，此处为“每天生产甲乙两种产品的数量”。然后是<strong>目标函数</strong>，即我们希望最小化（或最大化）的目标，此处为“每天生产的净收益”。最后，如果因为现实因素，我们的决策变量不能任意选取，那么还需要考虑<strong>约束条件</strong>，此处为“每天的A、B两种配料的供给和工作时长限制”。</p>
<p>如果我们设每天生产甲产品$x_1$件，生产乙产品$x_2$件，那么很容易列出下面的方程：<br>\begin{align*}<br>\max_{x_1,x_2} 2x_1&amp;+3x_2 \\<br>4x_1&amp;\leq 16 （约束：A配件）\\<br>4x_2&amp;\leq 12 （约束：B配件）\\<br>x_1+2x_2&amp;\leq 8 （约束：工作时间）<br>\end{align*}</p>
<h1 id="二、优化问题的一般形式"><a href="#二、优化问题的一般形式" class="headerlink" title="二、优化问题的一般形式"></a>二、优化问题的一般形式</h1><p>由此可见，确定了决策变量、目标函数、约束这三个要素之后，即可将优化问题转化为数学形式，而列出数学形式是求解优化问题的前提条件。我们可以将上面的例子作一般化的推广，把优化问题描述为如下形式：<br>\begin{equation*}<br>\min_x f(x) \\<br>\text{s.t. }x\in \mathcal{X}<br>\end{equation*}</p>
<p>其中$x$为决策变量，$f(x)$为目标函数；而$\mathcal{X}$则是约束。所谓优化问题的建模，不过是回答如下问题：决策变量$x$有哪些？目标函数$f(x)$如何描述？约束$\mathcal{X}$是什么形式？解决了这几个问题，我们就可以把优化问题描述成标准的数学形式。</p>
<p>在这三个要素中，决策变量和目标函数是必须存在的，约束则不一定（或许不应该称作“要素”）。也有很多优化问题，其决策变量并不受约束，或者约束很宽松，可以忽略，我们称作“无优化约束”，它们的求解是解决含优化约束问题的基础。</p>
<p>当然，上面的例子只是实际问题的一个特例，甚至算特例中的特例。为什么这么说？首先，这是一个<strong>确定性规划</strong>，我们生产$x_1$件甲产品，$x_2$件乙产品，那么获得的利润一定是$2x_1+3x_2$，同时，每天都是严格的8小时工作制，配件厂每天提供的配件也是固定的。那么有没有可能每天的客户需求是有变化的？工厂的设备和工人的工作效率都是恒定的吗？配件厂每天都有足量的配件吗？诚然，在实际生产中，我们有诸多措施（例如合同等）来保障意外情况不会发生，但在有的生产环境中，这些不确定性是有必要考虑的。</p>
<p>不仅如此，这个问题还是一个<strong>线性规划</strong>——目标函数和约束都是线性的。同样，我们可以提出一些问题：生产产品的总利润是正比于产品数量的吗？有没有规模效应？生产产品数量多的时候，速度会不会加快？诸如此类，都会让问题变得更加复杂。</p>
<p>如何选取模型是一个很复杂的问题，难以用统一的标准来衡量。简单来说，越精细的模型，通常计算难度越大，甚至有的模型目前为止还没有很好的求解方法。因此，选取模型的时候需要在准确性和求解难度之间进行权衡。</p>
<h1 id="三、小结"><a href="#三、小结" class="headerlink" title="三、小结"></a>三、小结</h1><p>决策变量、目标函数、约束，这些内容对于做优化的人来说，是很基础的内容，每个人都耳熟能详。在优化的教科书中，这几个术语也不过是几行定义。但在科研和交流的过程中，我曾见到过一些甚至研究生高年级的同学，在这个方面仍然会犯常识性错误。参加我们学科（电力系统）最大的学术年会，也看到一些做系统优化的人对研究成果中的明显错误毫无概念——以为自己做了随机优化，实际上是确定性优化；以为自己的结果是解复杂优化算出来的，实际上问题只有平凡解，诸如此类。</p>
<p>每个人都知道怎么用商业软件求解优化问题，但商业软件并不能告诉我们优化目标是否合理，约束形式是否正确，以及一个变量该不该作为决策变量。我曾经看到过一类很热门的研究，采用的优化模型和实际并不相符。当然，采用简化的模型无可厚非。但令人吃惊的是，绝大多数用这个模型做研究的人，丝毫没有意识到这是一个有很大程度简化的模型——他们只是很放心大胆地在使用。</p>
<p>对于做工程学科的人来说，掌握数学工具当然是好的，但在使用数学工具之前，总得明白自己的问题是什么。所以，我们在做优化之前，还是要牢记这样几个问题：<strong>决策变量是什么？目标是什么？约束是什么？</strong></p>
]]></content>
      
        <categories>
            
            <category> 优化 </category>
            
            <category> 模型 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 优化 </tag>
            
            <tag> 模型 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[双线性约束的精确松弛]]></title>
      <url>/articles/bilinear.html</url>
      <content type="html"><![CDATA[<p>今天想谈一个研究中常见的问题，即含有双线性约束的优化问题。<br>双线性约束即形为$z=xy$的约束，这是一类在电力领域中很常见的约束。对于含有一般双线性约束的优化问题，目前还没有很好的求解方法，不过，有一些特殊的双线性约束是可以被等价转化成线性约束的，本文即讨论这些约束形式以及相应的转化技巧。<br><a id="more"></a></p>
<p>原创内容: cxsmarkchan</p>
<h1 id="1-双线性约束举例"><a href="#1-双线性约束举例" class="headerlink" title="1 双线性约束举例"></a>1 双线性约束举例</h1><p><strong>之所以说双线性约束$z=xy$难以求解，是因为它不仅是非线性的，而且是非凸的。</strong>关于凸性可以参考<a href="https://en.wikipedia.org/wiki/Convex_set" target="_blank" rel="external">Wikipedia</a>的解释。对于这个问题，简单来说，是指如果三维空间中的两个点$x_1,y_1,z_1$和$x_2,y_2,z_2$都满足约束，即$z_1=x_1y_1,z_2=x_2y_2$，那么这两点所连接的线段上的点$\left(x,y,z\right)$是否也满足$\left(z=xy\right)$。很明显，双线性约束不满足这个条件。例如，$(1,2,2)$和$(2,4,8)$都满足$z=xy$的条件，但是它们的中点$(1.5,3,5)$显然不满足条件。</p>
<p><strong>目前，我们的数学工具能在很大程度上求解凸优化问题，但对于非凸优化问题，目前还没有很成熟的求解方法。</strong>这也是含双线性约束的优化问题让人头疼的原因。不巧的是，在电力领域的研究中，很难回避双线性问题。举几个简单的例子：</p>
<ol>
<li>功率约束$P=UI$本身就是双线性的，这意味着所有的交流潮流问题都是双线性问题。</li>
<li>电网中，上网电价和用电电价是不相等的。在这种情况下，储能系统充电和放电的情况要分开考虑。储能从电网充电的成本是$\lambda^+ P^+$，其中$\lambda^+$是用电电价，$P^+$是充电功率。而储能向电网放电的收益是$\lambda^- P^-$，其中$\lambda^-$是上网电价，$P^-$是放电功率。很明显，同一个时刻，储能要么充电、要么放电，因此必然有$P^+P^-=0$，这也是个双线性问题。</li>
<li>电力市场中的博弈行为常常涉及多层优化问题，动态博弈的均衡点求解需要用到互补松弛条件，这也是一个双线性的条件。</li>
<li>在电网规划或者状态估计中，会遇到一些含逆运算的约束问题（例如导纳和阻抗的关系），即$z=y^{-1}$的问题。这里的$y$会受到一个操作的影响，即$y=y_0+b\Delta y$，其中b是0-1变量，表示我们是否执行了该操作。未执行操作时，$y=y_0$；执行操作时，$y=y_0+\Delta y$。这样，约束就变成了$z=(y_0+b\Delta y)^{-1}$，即$y_0z+bz\Delta y=1$。其中的$bz$就是双线性项。</li>
</ol>
<p>其中，第一个问题可以说是电力系统稳态分析的一个痛点。对于辐射网，目前已经有了一些比较好的解决方法，可以参考Steven Low关于最优潮流的研究成果。但对于一般的网络，只能考虑求取次优解。这篇博客不打算讨论该问题，但以后有时间的话，我会争取把我了解到的相关研究整理出来。</p>
<p>问题2到问题4都可以通过一定的技巧转化成（含整数的）线性问题，这也是后文讨论的重点。</p>
<h1 id="2-双线性约束的标准形式"><a href="#2-双线性约束的标准形式" class="headerlink" title="2 双线性约束的标准形式"></a>2 双线性约束的标准形式</h1><p>双线性在优化问题中可以有多种形式，以下面的优化问题为例：</p>
<p>\[<br>\begin{aligned}<br>\text{min } &amp; x_1 + x_2x_3 \\<br>\text{s.t. } &amp; x_2 \leq x_4x_5 \\<br>&amp; x_3 = x_6\left(x_7 + 2\right)<br>\end{aligned}<br>\]</p>
<p>这个方程里面含有三个双线性部分，第一个在目标函数中，第二个在不等式约束中，第三个则在等式约束中。粗略看来，在不同位置的非线性量通常要用不同的方法来处理，但事实上，我们可以通过一定的变换，把这些双线性部分用标准形式来表达。</p>
<p>所谓标准形式，是指形如$z=xy$的约束。例如上述优化问题，我们也可以用如下形式表达：</p>
<p>\[<br>\begin{aligned}<br>\text{min } &amp; x_1 + z_1 \\<br>\text{s.t. } &amp; x_2 \leq z_2 \\<br>&amp; x_3 = x_6z_3 \\<br>&amp; z_1 = x_2x_3 \\<br>&amp; z_2 = x_4x_5 \\<br>&amp; z_3 = x_7 + 2 \\<br>\end{aligned}<br>\]</p>
<p>很容易看出，转化后的形式和转化前的形式相比，实际上只是做了几个变量替换，但目标函数中已经不存在双线性量，而且所有的双线性量都出现在了等式约束中。通过这样的转化，我们就可以把主要精力集中在对标准双线性形式的处理上。</p>
<h1 id="3-双线性约束的精确松弛"><a href="#3-双线性约束的精确松弛" class="headerlink" title="3 双线性约束的精确松弛"></a>3 双线性约束的精确松弛</h1><h2 id="3-1-利用目标函数实现精确松弛"><a href="#3-1-利用目标函数实现精确松弛" class="headerlink" title="3.1 利用目标函数实现精确松弛"></a>3.1 利用目标函数实现精确松弛</h2><p>对于第1节提到的问题2，其约束为$P^+P^-=0$。这个约束并不是单独出现的，而是一般会出现在和储能有关的优化问题中。这类优化问题的一般形式如下：</p>
<p>\[<br>\begin{aligned}<br>\text{min } &amp; \lambda^+P^+ - \lambda^-P^- \\<br>\text{s.t.} &amp; P^+ \geq 0,P^- \geq 0 \\<br>&amp; P^+P^-=0 \\<br>&amp; f\left(P^+ - P^-\right) \leq 0<br>\end{aligned}<br>\]</p>
<p>其中，最后一个条件表示，对于外界来说，只有储能实际的出力，即$P^+ - P^-$是受到关心的。也就是说，在不考虑前两个约束时，$P^+$和$P^-$同时增加或降低一个数，对外界来说是没有影响的。</p>
<p>同时，一般来说，上网电价会低于用电电价，即$\lambda^+ &gt; \lambda^- $。其直观的意义是：储能在某个时刻，充一定量的电，再把这些点送回电网，那么电网会收取过网费，因此储能会亏损。</p>
<p>在这两个条件下，我们会发现，双线性的互补松弛约束完全可以删去。这是因为，储能把最小化成本作为目标函数，那么它一定不会选择在同一时刻“既充电又放电”的决策，因为这个决策是亏损的。既然优化问题的目标函数使得这种决策不会被选择，我们就没必要在约束条件中禁止这种决策的出现——即使出现了，也不会成为最优策略！</p>
<p>因此，利用目标函数的特性，我们把问题改写成了如下格式：</p>
<p>\[<br>\begin{aligned}<br>\text{min } &amp; \lambda^+P^+ - \lambda^-P^- \\<br>\text{s.t.} &amp; P^+ \geq 0,P^- \geq 0 \\<br>&amp; f\left(P^+ - P^-\right) \leq 0<br>\end{aligned}<br>\]</p>
<p>这个方法的关键在于：我们一般会在约束条件中禁止一些不合要求的策略（例如储能既充电又放电是不符合实际的），但如果这个策略本身不可能是最优策略，那么我们也就没必要在约束条件中禁止它了。</p>
<h2 id="3-2-利用大数实现精确松弛"><a href="#3-2-利用大数实现精确松弛" class="headerlink" title="3.2 利用大数实现精确松弛"></a>3.2 利用大数实现精确松弛</h2><p>3.1节的方法只适合于目标函数“比较配合”的情形，对于一般的互补松弛约束（如问题3）是不适用的。这种情况下，我们还可以采用大数的方法松弛。</p>
<p>例如一个$xy=0,x \geq 0, y \geq 0$的约束，我们可以引入两个0-1整数变量$b_1,b_2$和一个很大的数$M$，并把约束改写成如下形式：<br>\[<br>0 \leq x \leq b_1M \\<br>0 \leq y \leq b_2M \\<br>b_1 + b_2 \leq 1<br>\]</p>
<p>以上形式是含整数的线性约束。注意到$b_1,b_2$是0-1变量，因此第3个约束保证了$b_1$和$b_2$最多只有1个是1，或者说，至少有1个是0。</p>
<p>那么$b_1$和$b_2$的值有什么意义呢？我们以$b_1$为例：</p>
<ul>
<li>如果$b_1=0$，第1个约束变成了$0 \leq x \leq 0$，也就是$x=0$</li>
<li>如果$b_1=1$，第1个约束变成了$0 \leq x \leq M$，由于$M$是一个很大的数，超过了$x$可能的取值返回，我们可以认为$M$对$x$不产生约束。因此，该约束就变成了$x \geq 0$</li>
</ul>
<p>由此可见，$b_1$和$b_2$最少有1个是0，也就意味着$x$和$y$最少有1个是0，因此互补松弛约束也就满足了。这样，互补松弛约束就被等价变换成了含整数的线性约束。</p>
<p>大数和整数变量还可以用于问题4的精确松弛。问题4中的关键部分在于$bz$，我们可以写成$w=bz$的形式，其中$w$和$z$是连续变量，$b$是0-1变量。$w=bz$可以被改写成如下形式：</p>
<p>\[<br>\left| w \right| \leq bM \\<br>\left| w - z \right| \leq (1-b)M \\<br>\]</p>
<p>注意到$b=0$时，第1个约束收紧为$w=0$，第2个约束因为$M$很大而不起作用；$b=1$时，第1个约束不起作用，第2个约束收紧为$w-z=0$。因此，这两个式子和$w=bz$是等价的：在$b=0$时，$w=0$；在$b=1$时，$w=z$。</p>
<p>相关参考文献：</p>
<ol>
<li>关于问题1中非线性约束在辐射网中的求解，可参考：M. Farivar and S. H. Low, “Branch Flow Model: Relaxations and Convexification—Part I,” in IEEE Transactions on Power Systems, vol. 28, no. 3, pp. 2554-2564, Aug. 2013.</li>
<li>关于问题3中互补松弛约束的求解，可参考：C. Ruiz and A. J. Conejo, “Pool Strategy of a Producer With Endogenous Formation of Locational Marginal Prices,” in IEEE Transactions on Power Systems, vol. 24, no. 4, pp. 1855-1866, Nov. 2009.</li>
<li>关于问题4中求逆问题的求解，可参考：X. Chen; J. Lin; C. Wan; Y. Song; S. You; Y. Zong; W. Guo; Y. Li, “Optimal Meter Placement for Distribution Network State Estimation: A Circuit Representation Based MILP Approach,” in IEEE Transactions on Power Systems (Early Access)</li>
</ol>
]]></content>
      
        <categories>
            
            <category> 优化 </category>
            
            <category> 模型 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 双线性 </tag>
            
            <tag> 优化 </tag>
            
            <tag> 松弛 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[linux源码分析：schedule进程调度]]></title>
      <url>/articles/linux-schedule.html</url>
      <content type="html"><![CDATA[<p>schedule是linux中的一个内核函数，用于实现进程调度。该函数由内核线程在合适的时机调用，完成进程上下文的切换。本文从源码的角度分析了schedule函数的执行过程，尤其是进程上下文的切换过程。本文所分析的源码来自<a href="http://codelab.shiyanlou.com/xref/linux-3.18.6/" target="_blank" rel="external">这里</a></p>
<a id="more"></a>
<p>原创内容：cxsmarkchan 陈晓爽<br>转载请注明出处<br><a href="http://www.xuetangx.com/courses/course-v1:ustcX+USTC001+_/about" target="_blank" rel="external">linux内核分析</a></p>
<h1 id="1-进程调度的基本方法"><a href="#1-进程调度的基本方法" class="headerlink" title="1 进程调度的基本方法"></a>1 进程调度的基本方法</h1><p>进程调度是操作系统的核心部分，操作系统的大多数行为，都可以概括为“从一个进程切换到另一个进程”。进程调度的时候，通常需要如下步骤：</p>
<ol>
<li>选择下一个要调度的进程</li>
<li>保存当前进程的上下文</li>
<li>切换到下一个进程的上下文</li>
</ol>
<p>linux系统在很多位置都会调用schedule函数，典型的调用场景如下：</p>
<ul>
<li>系统进行常规的进程调度</li>
<li>在系统调用或其他中断的时候，会允许进行进程调度</li>
<li>内核线程主动进行进程调度</li>
</ul>
<h1 id="2-schedule函数的执行过程"><a href="#2-schedule函数的执行过程" class="headerlink" title="2 schedule函数的执行过程"></a>2 schedule函数的执行过程</h1><h2 id="2-1-schedule函数"><a href="#2-1-schedule函数" class="headerlink" title="2.1 schedule函数"></a>2.1 schedule函数</h2><p>schedule函数定义在<code>kernel/sched/core.c</code>中，其定义如下：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">asmlinkage __visible <span class="keyword">void</span> __<span class="function">sched <span class="title">schedule</span><span class="params">(<span class="keyword">void</span>)</span></span><br><span class="line"></span>&#123;</span><br><span class="line">	<span class="keyword">struct</span> task_struct *tsk = current;</span><br><span class="line"></span><br><span class="line">	sched_submit_work(tsk);</span><br><span class="line">	__schedule();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>可见其最主要的内容是调用了<code>__schedule</code>函数。</p>
<h2 id="2-2-schedule函数"><a href="#2-2-schedule函数" class="headerlink" title="2.2 __schedule函数"></a>2.2 __schedule函数</h2><p><code>__schedule</code>函数执行了所有的进程调度工作。其主要功能为：</p>
<ol>
<li>获取当前进程和下一个进程的进程控制块</li>
<li>判断当前进程和下一个进程是否相同，如果不同，则调用<code>switch_context</code>函数</li>
</ol>
<p><code>__schedule</code>函数的重要代码如下：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">static</span> <span class="keyword">void</span> __sched __schedule(<span class="keyword">void</span>)</span><br><span class="line">&#123;</span><br><span class="line">	<span class="keyword">struct</span> task_struct *prev, *next;</span><br><span class="line">	<span class="keyword">unsigned</span> <span class="keyword">long</span> *switch_count;</span><br><span class="line">	<span class="keyword">struct</span> rq *rq;</span><br><span class="line">	<span class="keyword">int</span> cpu;</span><br><span class="line">    </span><br><span class="line">need_resched:</span><br><span class="line">    preempt_disable();</span><br><span class="line">	cpu = smp_processor_id();</span><br><span class="line">	rq = cpu_rq(cpu);</span><br><span class="line">	prev = rq-&gt;curr; <span class="comment">//获取了当前进程的进程控制块</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">/* ... */</span></span><br><span class="line"></span><br><span class="line">	next = pick_next_task(rq, prev); <span class="comment">//获取了下一个进程的进程控制块</span></span><br><span class="line">	clear_tsk_need_resched(prev);</span><br><span class="line">	clear_preempt_need_resched();</span><br><span class="line">	rq-&gt;skip_clock_update = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">if</span> (likely(prev != next)) &#123; <span class="comment">//判断当前进程和下一个进程是否相同</span></span><br><span class="line">		rq-&gt;nr_switches++;</span><br><span class="line">		rq-&gt;curr = next;</span><br><span class="line">		++*switch_count;</span><br><span class="line"></span><br><span class="line">		context_switch(rq, prev, next); <span class="comment">//切换进程上下文</span></span><br><span class="line">        </span><br><span class="line">		cpu = smp_processor_id();</span><br><span class="line">		rq = cpu_rq(cpu);</span><br><span class="line">	&#125; <span class="keyword">else</span></span><br><span class="line">		raw_spin_unlock_irq(&amp;rq-&gt;lock);</span><br><span class="line"></span><br><span class="line">	post_schedule(rq);</span><br><span class="line">	sched_preempt_enable_no_resched();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h2 id="2-3-pick-next-task函数"><a href="#2-3-pick-next-task函数" class="headerlink" title="2.3 pick_next_task函数"></a>2.3 pick_next_task函数</h2><p>pick_next_task函数位于<code>kernel/sched/core.c</code>，其功能为获取下一个进程的进程控制块。其源码如下：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">inline</span> <span class="keyword">struct</span> task_struct *</span><br><span class="line"><span class="title">pick_next_task</span><span class="params">(<span class="keyword">struct</span> rq *rq, <span class="keyword">struct</span> task_struct *prev)</span></span><br><span class="line"></span>&#123;</span><br><span class="line">	<span class="keyword">const</span> <span class="keyword">struct</span> sched_class *<span class="keyword">class</span> = &amp;fair_sched_class;</span><br><span class="line">	<span class="keyword">struct</span> task_struct *p;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">if</span> (likely(prev-&gt;sched_class == <span class="keyword">class</span> &amp;&amp;</span><br><span class="line">		   rq-&gt;nr_running == rq-&gt;cfs.h_nr_running)) &#123;</span><br><span class="line">		p = fair_sched_class.pick_next_task(rq, prev); <span class="comment">//进程调度算法</span></span><br><span class="line">		<span class="keyword">if</span> (unlikely(p == RETRY_TASK))</span><br><span class="line">			<span class="keyword">goto</span> again;</span><br><span class="line"></span><br><span class="line">		<span class="comment">/* assumes fair_sched_class-&gt;next == idle_sched_class */</span></span><br><span class="line">		<span class="keyword">if</span> (unlikely(!p))</span><br><span class="line">			p = idle_sched_class.pick_next_task(rq, prev); <span class="comment">//进程调度算法</span></span><br><span class="line"></span><br><span class="line">		<span class="keyword">return</span> p;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">again:</span><br><span class="line">	for_each_class(<span class="keyword">class</span>) &#123;</span><br><span class="line">		p = <span class="keyword">class</span>-&gt;pick_next_task(rq, prev); <span class="comment">//进程调度算法</span></span><br><span class="line">		<span class="keyword">if</span> (p) &#123;</span><br><span class="line">			<span class="keyword">if</span> (unlikely(p == RETRY_TASK))</span><br><span class="line">				<span class="keyword">goto</span> again;</span><br><span class="line">			<span class="keyword">return</span> p;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	BUG(); <span class="comment">/* the idle class will always have a runnable task */</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>可见，该函数中3次调用了名为pick_next_task的函数。事实上，这3个pick_next_task均为函数指针，指向了3个不同的函数。也就是说，在不同的情况下，linux会选择不同的算法来获取下一个要执行的进程。</p>
<h2 id="2-4-context-switch函数和switch-to函数"><a href="#2-4-context-switch函数和switch-to函数" class="headerlink" title="2.4 context_switch函数和switch_to函数"></a>2.4 context_switch函数和switch_to函数</h2><p><code>context_switch</code>函数位于<code>kernel/sched/core.c</code>，其主要功能是执行进程调度。此处不再列举其源码，因为在源码中，最重要的一条语句即为：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">switch_to(prev, next, prev);</span><br></pre></td></tr></table></figure>
<p>该语句的任务是执行进程上下文的切换。对于不同的CPU指令集，进程上下文切换的步骤也不同，因此<code>switch_to</code>是存放在<code>arch</code>目录中的。对于x86指令集，该函数位于<code>arch/x86/include/asm/switch_to.h</code>，其源码如下：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">define</span> switch_to(prev, next, last)					\</span><br><span class="line">do &#123;									\</span><br><span class="line">	unsigned long ebx, ecx, edx, esi, edi;				\</span><br><span class="line">	asm volatile(<span class="string">"pushfl\n\t"</span>		<span class="comment">/* 保存进程标志 */</span>	\</span><br><span class="line">		     <span class="string">"pushl %%ebp\n\t"</span>		<span class="comment">/* 保存prev进程的堆栈底端   */</span>	\</span><br><span class="line">		     <span class="string">"movl %%esp,%[prev_sp]\n\t"</span>	<span class="comment">/* 将prev进程的堆栈信息存入prev的进程控制块中   */</span> \</span><br><span class="line">		     <span class="string">"movl %[next_sp],%%esp\n\t"</span>	<span class="comment">/* 从next进程的进程控制块中调出堆栈位置信息   */</span> \</span><br><span class="line">		     <span class="string">"movl $1f,%[prev_ip]\n\t"</span>	<span class="comment">/* 将$1位置存入prev的进程控制块，作为下次调用的起点   */</span>	\</span><br><span class="line">		     <span class="string">"pushl %[next_ip]\n\t"</span>	<span class="comment">/* 将next进程的当前语句压栈   */</span>	\</span><br><span class="line">		     __switch_canary					\</span><br><span class="line">		     <span class="string">"jmp __switch_to\n"</span>	<span class="comment">/* 跳转到__switch_to函数，由于没有执行call语句，因此堆栈中的返回位置是next_ip  */</span>	\</span><br><span class="line">             <span class="comment">/* 从__switch_to中返回时，进程上下文已切换至next进程，并执行$1位置 */</span></span></span><br><span class="line">		     <span class="string">"1:\t"</span>					<span class="comment">/* $1位置，进程继续执行的位置 */</span>	\</span><br><span class="line">		     <span class="string">"popl %%ebp\n\t"</span>		<span class="comment">/* 弹出next进程的堆栈底端   */</span>	\</span><br><span class="line">		     <span class="string">"popfl\n"</span>			<span class="comment">/* 恢复进程标志 */</span>	\</span><br><span class="line">									\</span><br><span class="line">		     <span class="comment">/* output parameters */</span>				\</span><br><span class="line">		     : [prev_sp] <span class="string">"=m"</span> (prev-&gt;thread.sp),		\</span><br><span class="line">		       [prev_ip] <span class="string">"=m"</span> (prev-&gt;thread.ip),		\</span><br><span class="line">		       <span class="string">"=a"</span> (last),					\</span><br><span class="line">									\</span><br><span class="line">		       <span class="comment">/* clobbered output registers: */</span>		\</span><br><span class="line">		       <span class="string">"=b"</span> (ebx), <span class="string">"=c"</span> (ecx), <span class="string">"=d"</span> (edx),		\</span><br><span class="line">		       <span class="string">"=S"</span> (esi), <span class="string">"=D"</span> (edi)				\</span><br><span class="line">		       							\</span><br><span class="line">		       __switch_canary_oparam				\</span><br><span class="line">									\</span><br><span class="line">		       <span class="comment">/* input parameters: */</span>				\</span><br><span class="line">		     : [next_sp]  <span class="string">"m"</span> (next-&gt;thread.sp),		\</span><br><span class="line">		       [next_ip]  <span class="string">"m"</span> (next-&gt;thread.ip),		\</span><br><span class="line">		       							\</span><br><span class="line">		       <span class="comment">/* regparm parameters for __switch_to(): */</span>	\</span><br><span class="line">		       [prev]     <span class="string">"a"</span> (prev),				\</span><br><span class="line">		       [next]     <span class="string">"d"</span> (next)				\</span><br><span class="line">									\</span><br><span class="line">		       __switch_canary_iparam				\</span><br><span class="line">									\</span><br><span class="line">		     : <span class="comment">/* reloaded segment registers */</span>			\</span><br><span class="line">			<span class="string">"memory"</span>);					\</span><br><span class="line">&#125; <span class="keyword">while</span> (<span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<p>这段程序分为保存现场和恢复现场两部分。保存现场的内容包括：</p>
<ol>
<li>压栈保存flag</li>
<li>压栈保存ebp信息</li>
<li>将sp存入进程控制块的sp中</li>
<li>将<code>$1</code>存入进程控制块的ip中</li>
</ol>
<p>这里值得注意的是：保存ip信息时，并没有把当前的ip存入进程控制块，这是因为，下次恢复现场的时候，并不希望从当前ip处执行，而是希望从当前ip的后面几句，即<code>$1</code>处开始执行。</p>
<p>恢复现场的内容包括：</p>
<ol>
<li>从进程控制块中取出sp</li>
<li>从进程控制块中取出ip并压栈</li>
<li>用jmp而不是call调用__switch_to函数（用call时会将当前ip压栈，这并不是我们期望的，因为next_ip已经压栈了），在函数返回时的ret将栈顶的ip弹出到程序指针处</li>
<li>弹栈恢复ebp信息</li>
<li>弹栈恢复flag信息</li>
</ol>
<p>理解这段程序时，应该注意：next进程在上一次切换时，也执行了保存现场的语句，因此next进程的现场和prev进程的现场在结构上是相同的。</p>
<h1 id="3-小结"><a href="#3-小结" class="headerlink" title="3 小结"></a>3 小结</h1><p>在linux系统中，进程调度是很重要的一部分。linux系统的一般执行过程即为“从一个进程切换到另一个进程”。进程切换通过调用schedule函数来完成，其中最主要的内容即为进程上下文的切换。</p>
]]></content>
      
        <categories>
            
            <category> linux </category>
            
            <category> 源码 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> linux </tag>
            
            <tag> 源码 </tag>
            
            <tag> 进程 </tag>
            
            <tag> schedule </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[linux源码分析：execve加载可执行文件]]></title>
      <url>/articles/linux-execve.html</url>
      <content type="html"><![CDATA[<p>execve是linux中一个重要的系统调用，它用于将一个可执行文件加载如内存中并执行。在执行shell命令时，就会调用execve函数。有意思的是，execve并未创建新的进程，而是会把当前进程覆盖。本文分析execve的实现过程，以加深对linux可执行文件加载过程的理解。本文分析的源码来自<a href="http://codelab.shiyanlou.com/xref/linux-3.18.6" target="_blank" rel="external">这里</a><br><a id="more"></a></p>
<p>原创内容： cxsmarkchan 陈晓爽<br>转载请注明出处<br><a href="http://www.xuetangx.com/courses/course-v1:ustcX+USTC001+_/about" target="_blank" rel="external">Linux内核分析</a>学习笔记</p>
<h1 id="1-execve的使用方法"><a href="#1-execve的使用方法" class="headerlink" title="1 execve的使用方法"></a>1 execve的使用方法</h1><p>execve的调用格式如下：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">execve</span><span class="params">(<span class="keyword">const</span> <span class="keyword">char</span> * filename,<span class="keyword">char</span> * <span class="keyword">const</span> argv[ ],<span class="keyword">char</span> * <span class="keyword">const</span> envp[ ])</span></span>;</span><br></pre></td></tr></table></figure></p>
<p>按照linux一切皆文件的思想，加载可执行程序，实际上是把一个二进制文件加载入内存。其中，<code>filename</code>为可执行文件名，<code>argv</code>为输入的参数，<code>envp</code>为环境参数。在执行shell命令时，我们只需输入filename和argv，而envp则由系统自动赋值。<br>为了演示execve的使用，首先看下面一段C代码：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;unistd.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">char</span>* str[] = &#123;<span class="string">"ls"</span>&#125;;</span><br><span class="line">    execve(<span class="string">"/bin/ls"</span>, str, <span class="literal">NULL</span>);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">"ls done!\n"</span>);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>这段代码中用execve调用了linux的ls进程，用于显示当前目录下的文件。假设当前目录下有<code>test.cpp</code>和<code>a.out</code>两个文件，猜一下这段程序的运行结果是什么呢？从直觉上看，似乎应该是这样：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">test.cpp a.out</span><br><span class="line">ls done!</span><br></pre></td></tr></table></figure></p>
<p>但实际上，运行结果是这样：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">test.cpp a.out</span><br></pre></td></tr></table></figure></p>
<p>执行完execve后，那句printf语句为什么没有被执行呢？这正是execve的神奇之处：它没有创建新进程，而是用新加载的可执行文件把当前进程覆盖了！因此，执行完execve后，printf语句早已不存在。<br>因此，调用execve的时候，我们通常用如下程序，先fork一个子进程，并在子进程中加载可执行文件：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">#include &lt;unistd.h&gt;</span><br><span class="line">#include &lt;sys/wait.h&gt;</span><br><span class="line">#include &lt;stdio.h&gt;</span><br><span class="line"></span><br><span class="line">int main() &#123;</span><br><span class="line">    char* str[] = &#123;&quot;ls&quot;&#125;;</span><br><span class="line">    int pid = fork();</span><br><span class="line">    if(pid == 0) &#123;</span><br><span class="line">        execve(&quot;/bin/ls&quot;, str, NULL);</span><br><span class="line">    &#125; else &#123;</span><br><span class="line">        wait(NULL); // 等待子进程返回</span><br><span class="line">        printf(&quot;ls done!\n&quot;);</span><br><span class="line">    &#125;</span><br><span class="line">    return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这段程序就可以得到预期的输出结果，即先输出ls的结果，再输出<code>ls done!</code>。</p>
<h1 id="2-execve源码分析"><a href="#2-execve源码分析" class="headerlink" title="2 execve源码分析"></a>2 execve源码分析</h1><h2 id="2-1-从execve到exec-binprm"><a href="#2-1-从execve到exec-binprm" class="headerlink" title="2.1 从execve到exec_binprm"></a>2.1 从execve到exec_binprm</h2><p>execve位于内核源码的<code>fs/exec.c</code>，其定义如下：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">SYSCALL_DEFINE3(execve,</span><br><span class="line">		<span class="keyword">const</span> <span class="keyword">char</span> __user *, filename,</span><br><span class="line">		<span class="keyword">const</span> <span class="keyword">char</span> __user *<span class="keyword">const</span> __user *, argv,</span><br><span class="line">		<span class="keyword">const</span> <span class="keyword">char</span> __user *<span class="keyword">const</span> __user *, envp)</span><br><span class="line">&#123;</span><br><span class="line">	<span class="keyword">return</span> do_execve(getname(filename), argv, envp);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">do_execve</span><span class="params">(<span class="keyword">struct</span> filename *filename,</span><br><span class="line">	<span class="keyword">const</span> <span class="keyword">char</span> __user *<span class="keyword">const</span> __user *__argv,</span><br><span class="line">	<span class="keyword">const</span> <span class="keyword">char</span> __user *<span class="keyword">const</span> __user *__envp)</span></span><br><span class="line"></span>&#123;</span><br><span class="line">	<span class="keyword">struct</span> user_arg_ptr argv = &#123; .ptr.native = __argv &#125;;</span><br><span class="line">	<span class="keyword">struct</span> user_arg_ptr envp = &#123; .ptr.native = __envp &#125;;</span><br><span class="line">	<span class="keyword">return</span> do_execve_common(filename, argv, envp);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>可见sys_execve函数调用了do_execve函数，而后者又调用了do_execve_common函数。do_execve_common函数中同样定义于<code>fs/exec.c</code>中，它包含了execve的主体部分，代码较长，我们只分析其中的主干部分：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">int</span> <span class="title">do_execve_common</span><span class="params">(<span class="keyword">struct</span> filename *filename,</span><br><span class="line">				<span class="keyword">struct</span> user_arg_ptr argv,</span><br><span class="line">				<span class="keyword">struct</span> user_arg_ptr envp)</span></span><br><span class="line"></span>&#123;</span><br><span class="line">	<span class="keyword">struct</span> linux_binprm *bprm; <span class="comment">//bprm用于维护程序执行的相关参数</span></span><br><span class="line">	<span class="keyword">struct</span> file *file;</span><br><span class="line">	<span class="keyword">int</span> retval;</span><br><span class="line"></span><br><span class="line">	bprm = kzalloc(<span class="keyword">sizeof</span>(*bprm), GFP_KERNEL);</span><br><span class="line">	retval = prepare_bprm_creds(bprm); <span class="comment">//分配creds结构体，处理锁信息</span></span><br><span class="line"></span><br><span class="line">	check_unsafe_exec(bprm);</span><br><span class="line">    current-&gt;in_execve = <span class="number">1</span>; <span class="comment">//表明当前进程正在执行新程序，这个在进程调度中有意义</span></span><br><span class="line"></span><br><span class="line">	file = do_open_exec(filename); <span class="comment">//打开文件</span></span><br><span class="line"></span><br><span class="line">	sched_exec(); <span class="comment">//进程调度</span></span><br><span class="line"></span><br><span class="line">	bprm-&gt;file = file;</span><br><span class="line">	bprm-&gt;filename = bprm-&gt;interp = filename-&gt;name;</span><br><span class="line"></span><br><span class="line">	retval = bprm_mm_init(bprm); <span class="comment">//初始化内存映射</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//以下内容为填充bprm，录入输入参数、环境参数等信息</span></span><br><span class="line">	bprm-&gt;argc = count(argv, MAX_ARG_STRINGS);</span><br><span class="line">	bprm-&gt;envc = count(envp, MAX_ARG_STRINGS);</span><br><span class="line">	retval = prepare_binprm(bprm);</span><br><span class="line">	retval = copy_strings_kernel(<span class="number">1</span>, &amp;bprm-&gt;filename, bprm);</span><br><span class="line">	bprm-&gt;exec = bprm-&gt;p;</span><br><span class="line">	retval = copy_strings(bprm-&gt;envc, envp, bprm);</span><br><span class="line">	retval = copy_strings(bprm-&gt;argc, argv, bprm);</span><br><span class="line"></span><br><span class="line">    <span class="comment">//装载程序</span></span><br><span class="line">    retval = exec_binprm(bprm);</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//还原信息和释放内存等</span></span><br><span class="line">    current-&gt;in_execve = <span class="number">0</span>;</span><br><span class="line">    free_bprm(bprm);</span><br><span class="line"></span><br><span class="line">	<span class="keyword">return</span> retval;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>在do_execve_common中，最重要的工作是构建bprm结构体</strong>。bprm结构体中包含了装载应用程序需要的所有信息，这些信息正是在do_execve_common中录入。这里应该重点关注bprm-&gt;p，它代表了应用程序堆栈的当前位置。我们知道，在调用一个应用程序时，相关参数实际上是main函数的参数，而参数的传入方式是通过堆栈传递。因此，在初始化应用程序的时候，必须首先把参数压栈。这个操作是在copy_strings_kernel和copy_strings函数中完成的(这些函数中会修改bprm-&gt;p)。当这些操作完成后，bprm-&gt;p已经指向了当前的堆栈顶端，因此装载可执行程序时，只需要把堆栈指向bprm-&gt;p，即可顺利执行。</p>
<p>构建完bprm后，do_execve_common调用了exec_binprm函数，装载应用程序。该函数定义如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">// exec_binprm</span><br><span class="line">// position: fs/exec.c</span><br><span class="line">static int exec_binprm(struct linux_binprm *bprm)</span><br><span class="line">&#123;</span><br><span class="line">	pid_t old_pid, old_vpid;</span><br><span class="line">	int ret;</span><br><span class="line"></span><br><span class="line">	/* Need to fetch pid before load_binary changes it */</span><br><span class="line">	old_pid = current-&gt;pid;</span><br><span class="line">	rcu_read_lock();</span><br><span class="line">	old_vpid = task_pid_nr_ns(current, task_active_pid_ns(current-&gt;parent));</span><br><span class="line">	rcu_read_unlock();</span><br><span class="line"></span><br><span class="line">	ret = search_binary_handler(bprm);</span><br><span class="line">	if (ret &gt;= 0) &#123;</span><br><span class="line">		audit_bprm(bprm);</span><br><span class="line">		trace_sched_process_exec(current, old_pid, bprm);</span><br><span class="line">		ptrace_event(PTRACE_EVENT_EXEC, old_vpid);</span><br><span class="line">		proc_exec_connector(current);</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	return ret;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p><strong>其中最关键的语句是search_binary_handler，其功能是根据可执行文件的格式，查找相应的处理程序。</strong>其定义如下(只列举了重要语句)：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">search_binary_handler</span><span class="params">(<span class="keyword">struct</span> linux_binprm *bprm)</span></span><br><span class="line"></span>&#123;</span><br><span class="line">	<span class="keyword">struct</span> linux_binfmt *fmt;</span><br><span class="line">	<span class="keyword">int</span> retval;</span><br><span class="line"></span><br><span class="line">	retval = security_bprm_check(bprm);</span><br><span class="line">    </span><br><span class="line">	read_lock(&amp;binfmt_lock);</span><br><span class="line">    <span class="comment">// 查找合适的处理程序</span></span><br><span class="line">	list_for_each_entry(fmt, &amp;formats, lh) &#123; <span class="comment">//遍历formats列表</span></span><br><span class="line">		<span class="keyword">if</span> (!try_module_get(fmt-&gt;module)) <span class="comment">//判断文件格式是否匹配</span></span><br><span class="line">			<span class="keyword">continue</span>;</span><br><span class="line">		read_unlock(&amp;binfmt_lock);</span><br><span class="line">		bprm-&gt;recursion_depth++;</span><br><span class="line">		retval = fmt-&gt;load_binary(bprm); <span class="comment">//处理程序</span></span><br><span class="line">		put_binfmt(fmt);</span><br><span class="line">		bprm-&gt;recursion_depth--;</span><br><span class="line">	&#125;</span><br><span class="line">	read_unlock(&amp;binfmt_lock);</span><br><span class="line">    </span><br><span class="line">	<span class="keyword">return</span> retval;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>该函数中用到了list_for_each_entry宏，这里不分析该宏的具体实现，只需知道它用于遍历formats中所有的列表项。formats列表中的每一项都是一个linux_binfmt结构体，代表了一种文件格式。每个变量中有一个名为load_binary的函数指针，指向相应的加载函数。例如，linux中最常用的ELF格式文件，其对应的加载函数即为load_elf_binary。这种实现方式类似于C++中的多态，也比较灵活，但内核实现需要借助很多宏，理解起来不如C++方便。<br><strong>在search_binary_handler中，formats被遍历，当找到匹配的文件格式时，load_binary函数即被调用。</strong>接下来，我们只分析load_elf_binary的源码。</p>
<h2 id="2-2-load-elf-binary"><a href="#2-2-load-elf-binary" class="headerlink" title="2.2 load_elf_binary"></a>2.2 load_elf_binary</h2><p>load_elf_binary位于<code>fs/binfmt_elf.c</code>，其代码很长，因为它需要对ELF格式的二进制文件进行解析。我们同样只看其中最主干的部分：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">int</span> <span class="title">load_elf_binary</span><span class="params">(<span class="keyword">struct</span> linux_binprm *bprm)</span></span><br><span class="line"></span>&#123;</span><br><span class="line">    <span class="comment">//大量变量定义，此处未完全列举</span></span><br><span class="line">	<span class="keyword">char</span> * elf_interpreter = <span class="literal">NULL</span>;</span><br><span class="line">	<span class="keyword">unsigned</span> <span class="keyword">long</span> elf_entry; <span class="comment">//进程入口</span></span><br><span class="line">	<span class="keyword">struct</span> pt_regs *regs = current_pt_regs(); <span class="comment">//当前的进程信息</span></span><br><span class="line">	<span class="keyword">struct</span> &#123;</span><br><span class="line">		<span class="keyword">struct</span> elfhdr elf_ex;</span><br><span class="line">		<span class="keyword">struct</span> elfhdr interp_elf_ex;</span><br><span class="line">	&#125; *loc; <span class="comment">//进程执行信息，包括进程入口等</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">////////////////////////////////////////////</span></span><br><span class="line">    <span class="comment">//文件解析工作，此处省略</span></span><br><span class="line">    <span class="comment">////////////////////////////////////////////</span></span><br><span class="line"></span><br><span class="line">	<span class="keyword">if</span> (elf_interpreter) &#123; <span class="comment">// 动态链接</span></span><br><span class="line">		<span class="keyword">unsigned</span> <span class="keyword">long</span> interp_map_addr = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">		elf_entry = load_elf_interp(&amp;loc-&gt;interp_elf_ex,</span><br><span class="line">					    interpreter,</span><br><span class="line">					    &amp;interp_map_addr,</span><br><span class="line">					    load_bias);</span><br><span class="line">                        </span><br><span class="line">		reloc_func_desc = interp_load_addr;</span><br><span class="line"></span><br><span class="line">		allow_write_access(interpreter);</span><br><span class="line">		fput(interpreter);</span><br><span class="line">		kfree(elf_interpreter);</span><br><span class="line">	&#125; <span class="keyword">else</span> &#123; <span class="comment">// 静态链接</span></span><br><span class="line">		elf_entry = loc-&gt;elf_ex.e_entry;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	kfree(elf_phdata);</span><br><span class="line"></span><br><span class="line">	set_binfmt(&amp;elf_format);</span><br><span class="line"></span><br><span class="line">    <span class="comment">/////////////////////////////////////////////////////////</span></span><br><span class="line">    <span class="comment">//此处省略了设置内存映射的相关内容</span></span><br><span class="line">    <span class="comment">/////////////////////////////////////////////////////////</span></span><br><span class="line"></span><br><span class="line">	start_thread(regs, elf_entry, bprm-&gt;p); <span class="comment">//启动进程</span></span><br><span class="line">    </span><br><span class="line">	retval = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">return</span> retval;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>该函数主要做了3部分工作：</strong></p>
<ol>
<li><strong>把可执行文件读入内存</strong></li>
<li><strong>根据读入的elf文件信息，设置可执行文件的入口</strong></li>
<li><strong>启动线程</strong></li>
</ol>
<p>从上述代码可见，在设置可执行文件入口的时候，需要根据程序是否有动态链接行为，决定进程的入口位置，此处不再展开说明。</p>
<h2 id="2-3-start-thread"><a href="#2-3-start-thread" class="headerlink" title="2.3 start_thread"></a>2.3 start_thread</h2><p>经过一番曲折，终于到了execve程序的末尾。上一节中load_elf_binary最后有这么一句话：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">start_thread(regs, elf_entry, bprm-&gt;p);</span><br></pre></td></tr></table></figure></p>
<p>这个语句即为启动新加载的程序了。在x86 32位系统中，start_thread定义在<code>arch/x86/kernel/process_32.c</code>中，如下：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">start_thread</span><span class="params">(<span class="keyword">struct</span> pt_regs *regs, <span class="keyword">unsigned</span> <span class="keyword">long</span> new_ip, <span class="keyword">unsigned</span> <span class="keyword">long</span> new_sp)</span></span><br><span class="line"></span>&#123;</span><br><span class="line">	set_user_gs(regs, <span class="number">0</span>);</span><br><span class="line">	regs-&gt;fs		= <span class="number">0</span>;</span><br><span class="line">	regs-&gt;ds		= __USER_DS;</span><br><span class="line">	regs-&gt;es		= __USER_DS;</span><br><span class="line">	regs-&gt;ss		= __USER_DS;</span><br><span class="line">	regs-&gt;cs		= __USER_CS;</span><br><span class="line">	regs-&gt;ip		= new_ip;</span><br><span class="line">	regs-&gt;sp		= new_sp;</span><br><span class="line">	regs-&gt;flags		= X86_EFLAGS_IF;</span><br><span class="line">    </span><br><span class="line">	set_thread_flag(TIF_NOTIFY_RESUME);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>注意我们传入的3个参数，第1个参数regs即为当前进程的注册信息，在load_elf_binary中定义。第2个参数new_ip是入口指令位置，在load_elf_binary中，由elf_entry指定。第3个参数new_sp是堆栈位置，传入参数为bprm-&gt;p，这个信息很早的时候，在do_execve_common函数中即设置完毕。有了这3个参数，start_thread可以顺利执行，可执行程序也就加载完毕。</p>
<h1 id="3-小结"><a href="#3-小结" class="headerlink" title="3 小结"></a>3 小结</h1><p>linux在装载和启动一个可执行程序的时候，主要做了如下工作：</p>
<ol>
<li>构建linux_binprm结构体，装载文件名、参数等信息，并完成堆栈信息的记录。</li>
<li>根据可执行文件的格式信息，查找相应的解析和加载程序。对于ELF程序，即为调用load_elf_binary函数。</li>
<li>在load_binary函数中，设置可执行程序的入口指令位置，并调用start_kernel，装入新的ip和sp，完成可执行程序的启动。</li>
</ol>
<p>值得注意的是，execve是在当前进程（调用execve函数的进程）上加载可执行文件，加载完毕后，原进程即被覆盖。如果不希望被覆盖，应该用fork创建新进程，再调用execve函数。</p>
]]></content>
      
        <categories>
            
            <category> linux </category>
            
            <category> 源码 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> linux </tag>
            
            <tag> 源码 </tag>
            
            <tag> execve </tag>
            
            <tag> 进程 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[linux源码分析：fork复制进程]]></title>
      <url>/articles/linux-fork.html</url>
      <content type="html"><![CDATA[<p>fork函数是linux系统的一个API，用于将当前进程复制，并创建一个新的进程。本文从linux源码的角度分析fork的实现过程，并学习linux创建新进程的过程。本文分析的源码来自<a href="http://codelab.shiyanlou.com/xref/linux-3.18.6" target="_blank" rel="external">这里</a>。<br><a id="more"></a></p>
<p>原创内容：cxsmarkchan 陈晓爽<br>转载请注明出处<br><a href="http://mooc.study.163.com/course/USTC-1000029000" target="_blank" rel="external">《Linux内核分析》MOOC课程</a>学习笔记</p>
<h1 id="1-fork函数"><a href="#1-fork函数" class="headerlink" title="1 fork函数"></a>1 fork函数</h1><p>在Linux系统下书写如下C语言代码：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;unistd.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">	<span class="keyword">int</span> pid = fork();</span><br><span class="line">	<span class="keyword">if</span>(pid &lt; <span class="number">0</span>)&#123;</span><br><span class="line">		<span class="built_in">printf</span>(<span class="string">"Failed!"</span>\n);</span><br><span class="line">	&#125;<span class="keyword">else</span> <span class="keyword">if</span>(pid == <span class="number">0</span>)&#123;</span><br><span class="line">		<span class="built_in">printf</span>(<span class="string">"This is Child Process!\n"</span>);</span><br><span class="line">	&#125;<span class="keyword">else</span>&#123;</span><br><span class="line">		<span class="built_in">printf</span>(<span class="string">"This is Parent Process!\n"</span>);</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>这样一段程序的执行结果如下（注意两条语句的执行顺序并不完全确定）：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">This is Parent Process!</span><br><span class="line">This is Child Process!</span><br></pre></td></tr></table></figure></p>
<p>有意思的事情是：两条输出语句被写在if-elseif-else语句的不同分支中，但输出时竟然两条语句均输出了！<br>这正是fork函数的作用：它把当前进程状态和相关数据都复制了一份，系统中有两个进程在运行。新生成的进程与原进程的状态完全相同，因此它也会“认为”自己调用了fork函数，并从fork()函数中返回。但是，两个进程的fork函数返回值并不相等。对于父进程，返回的pid是其子进程的pid。对于子进程，返回的pid则是0。因此，会出现两条输出语句。<br>接下来，我们会分析fork语句在linux源码中的实现。我们关心的重点是：</p>
<ul>
<li><strong>新进程的堆栈空间是如何分配的</strong></li>
<li><strong>新进程如何保证与原进程有相同的堆栈状态</strong></li>
<li><strong>新进程的起始执行点如何确定</strong></li>
<li><strong>如何使新进程的返回值和原进程不同**</strong></li>
</ul>
<h1 id="2-fork的源码分析"><a href="#2-fork的源码分析" class="headerlink" title="2 fork的源码分析"></a>2 fork的源码分析</h1><h2 id="2-1-linux的进程信息管理"><a href="#2-1-linux的进程信息管理" class="headerlink" title="2.1 linux的进程信息管理"></a>2.1 linux的进程信息管理</h2><p>linux系统为每个进程维护了一个task_struct类型的结构体变量，用于存储进程相关信息。task_struct结构定义于<code>include/linux/sched.h</code>，其代码约400行，包含进程的id、当前状态、内存信息、文件系统信息等。这里我们仅关系以下内容：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> task_struct&#123;</span><br><span class="line">    <span class="keyword">int</span> pid; <span class="comment">//进程id</span></span><br><span class="line">    <span class="keyword">void</span>* <span class="built_in">stack</span>; <span class="comment">//内核堆栈</span></span><br><span class="line">    <span class="keyword">struct</span> thread_struct thread; <span class="comment">//进程当前状态</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></p>
<p>其中，进程的id用于对进程进行唯一标识，进程的内核堆栈是操作系统为每个进程维护的一段空间（其内部包含用户堆栈和寄存器信息等），进程的当前状态则也是一个结构体，包含了进程的堆栈信息、当前运行位置、锁信息等。thread_struct在各种硬件环境中实现也不相同，在x86系统中，thread_struct定义于<code>arch/x86/include/asm/processor.h</code>。下面列出我们关心的内容：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> thread_struct&#123;</span><br><span class="line">    <span class="keyword">int</span> sp; <span class="comment">//堆栈顶端</span></span><br><span class="line">    <span class="keyword">int</span> ip; <span class="comment">//当前运行位置</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></p>
<p>因此，在创建新进程的时候，也需要给新进程分配id，分配内核堆栈stack，并初始化进程状态thread（在fork函数中，初始化的新进程状态应该与原进程完全相同，除了fork函数的返回值）。</p>
<h2 id="2-2-fork调用的全过程"><a href="#2-2-fork调用的全过程" class="headerlink" title="2.2 fork调用的全过程"></a>2.2 fork调用的全过程</h2><p>fork函数并不是一个普通的函数，而是一个系统调用，而系统调用是一个软件中断，在fork函数的调用过程中（中断返回前），会生成两个进程，因此生成的两个进程都仍处在中断状态，需要从中断状态返回。调用fork函数的父进程从中断过程返回是可以理解的，只需经过恢复现场的工作就可以了。但新生成的子进程，如何保证其初始化在中断状态，并从中断状态中返回呢？进一步地，如何让两个进程的返回值不相等呢？<br>下面的图可以简要地说明这种情况：<br><img src="/images/linux-fork/linux-fork-flowchart.jpg" alt="fork调用示意图"><br>在该图中可以看出，父进程仍然是正常的系统调用处理过程，但新建的新进程，则是复制了父进程的状态，并把当前语句设置在<code>ret_from_fork</code>标签处，该标签处执行一些初始化语句后，就跳转到<code>syscall_exit_work</code>处，退出中断状态。由于子进程和父进程的堆栈完全相同，因此返回的位置也完全相同。<br>而唯一不同的是两个进程的返回值，这一点的实现则是靠<code>ax</code>寄存器。<code>ax</code>寄存器中存储了系统调用的返回值，对于新进程来说，在<code>copy_thread</code>函数中将新进程的<code>ax</code>寄存器值设置为0，因此新进程的返回为0。<br>各个函数的位置如下：</p>
<ul>
<li>system_call: <code>arch/x86/kernel/entry_32.S</code></li>
<li>sys_fork: <code>kernel/fork.c</code></li>
<li>do_fork: <code>kernel/fork.c</code></li>
<li>copy_process: <code>kernel/fork.c</code></li>
<li>dup_task_struct: <code>kernel/fork.c</code></li>
<li>copy_thread: <code>arch/x86/kernel/process_32.c</code></li>
<li>ret_from_kernel: <code>arch/x86/kernel/entry_32.S</code></li>
</ul>
<p>以下会重点分析dup_task_struct和copy_thread函数，以及ret_from_kernel过程</p>
<h2 id="2-3-相关的函数分析"><a href="#2-3-相关的函数分析" class="headerlink" title="2.3 相关的函数分析"></a>2.3 相关的函数分析</h2><h3 id="2-3-1-dup-task-struct：创建进程"><a href="#2-3-1-dup-task-struct：创建进程" class="headerlink" title="2.3.1 dup_task_struct：创建进程"></a>2.3.1 dup_task_struct：创建进程</h3><p><strong>dup_task_struct用于创建一个新的进程，并把当前进程的信息复制到新进程（注意当前进程的运行状态不是在这里复制）。</strong>部分重要的源码和我的注释如下：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">struct</span> task_struct *<span class="title">dup_task_struct</span><span class="params">(<span class="keyword">struct</span> task_struct *orig)</span></span><br><span class="line"></span>&#123;</span><br><span class="line">	<span class="keyword">struct</span> task_struct *tsk; <span class="comment">//新进程的进程管理结构</span></span><br><span class="line">	<span class="keyword">struct</span> thread_info *ti; <span class="comment">//新进程的内核堆栈结构</span></span><br><span class="line">	<span class="keyword">int</span> node = tsk_fork_get_node(orig); </span><br><span class="line">    <span class="keyword">int</span> err;</span><br><span class="line"></span><br><span class="line">	tsk = alloc_task_struct_node(node); <span class="comment">//分配进程管理结构</span></span><br><span class="line">	<span class="keyword">if</span> (!tsk)</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">NULL</span>;</span><br><span class="line"></span><br><span class="line">	ti = alloc_thread_info_node(tsk, node); <span class="comment">//开辟内核堆栈</span></span><br><span class="line">	<span class="keyword">if</span> (!ti)</span><br><span class="line">		<span class="keyword">goto</span> free_tsk;</span><br><span class="line"></span><br><span class="line">	err = arch_dup_task_struct(tsk, orig); <span class="comment">//把orig的内容拷贝给tsk</span></span><br><span class="line">	<span class="keyword">if</span> (err)</span><br><span class="line">		<span class="keyword">goto</span> free_ti;</span><br><span class="line"></span><br><span class="line">	tsk-&gt;<span class="built_in">stack</span> = ti; <span class="comment">//把内核堆栈赋给tsk</span></span><br><span class="line"></span><br><span class="line">	setup_thread_stack(tsk, orig); <span class="comment">//初始化内核堆栈</span></span><br><span class="line"></span><br><span class="line">	<span class="keyword">return</span> tsk;</span><br><span class="line"></span><br><span class="line">free_ti:</span><br><span class="line">	free_thread_info(ti);</span><br><span class="line">free_tsk:</span><br><span class="line">	free_task_struct(tsk);</span><br><span class="line">	<span class="keyword">return</span> <span class="literal">NULL</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h3 id="2-3-2-copy-thread：复制进程状态"><a href="#2-3-2-copy-thread：复制进程状态" class="headerlink" title="2.3.2 copy_thread：复制进程状态"></a>2.3.2 copy_thread：复制进程状态</h3><p><strong>copy_thread用于把原进程的状态和堆栈拷贝到新进程，并设置返回值为0。</strong>部分重要的源码和我的注释如下：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">copy_thread</span><span class="params">(<span class="keyword">unsigned</span> <span class="keyword">long</span> clone_flags, <span class="keyword">unsigned</span> <span class="keyword">long</span> sp,</span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">long</span> arg, <span class="keyword">struct</span> task_struct *p)</span></span><br><span class="line"></span>&#123;</span><br><span class="line">    <span class="keyword">struct</span> pt_regs *childregs = task_pt_regs(p); <span class="comment">// 获取新进程的内核堆栈指针</span></span><br><span class="line">    </span><br><span class="line">    p-&gt;thread.sp = (<span class="keyword">unsigned</span> <span class="keyword">long</span>) childregs; <span class="comment">// 将新进程的堆栈设置为新分配的堆栈</span></span><br><span class="line">    *childregs = *current_pt_regs(); <span class="comment">// 复制所有的内核堆栈信息，包括寄存器信息和堆栈信息</span></span><br><span class="line">    childregs-&gt;ax = <span class="number">0</span>; <span class="comment">// 这句话把ax设置为0，因此新进程的系统调用返回值为0</span></span><br><span class="line">    <span class="keyword">if</span> (sp)</span><br><span class="line">	    childregs-&gt;sp = sp; <span class="comment">//复制当前堆栈信息</span></span><br><span class="line">    </span><br><span class="line">    p-&gt;thread.ip = (<span class="keyword">unsigned</span> <span class="keyword">long</span>) ret_from_fork; <span class="comment">// 设置新进程的入口位置</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>可见，该函数执行完毕后，新进程的堆栈和入口都已经确定，新进程启动时将处在中断状态，而中断返回值为0.</p>
<h3 id="2-3-3-ret-from-fork：退出中断"><a href="#2-3-3-ret-from-fork：退出中断" class="headerlink" title="2.3.3 ret_from_fork：退出中断"></a>2.3.3 ret_from_fork：退出中断</h3><p>这是新进程的第一条语句，当进程调度把CPU控制权交给新进程时，就会从该处向下执行。相关内容如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">ENTRY(ret_from_fork)</span><br><span class="line">	CFI_STARTPROC</span><br><span class="line">	pushl_cfi %eax</span><br><span class="line">	call schedule_tail</span><br><span class="line">	GET_THREAD_INFO(%ebp)</span><br><span class="line">	popl_cfi %eax</span><br><span class="line">	pushl_cfi $0x0202		# Reset kernel eflags</span><br><span class="line">	popfl_cfi</span><br><span class="line">	jmp syscall_exit</span><br><span class="line">	CFI_ENDPROC</span><br><span class="line">END(ret_from_fork)</span><br></pre></td></tr></table></figure></p>
<p>其中有一句<code>jmp syscall_exit</code>，而<code>syscall_exit</code>位于系统调用函数刚结束，正准备退出中断的位置。此时<code>ax</code>寄存器中存储了系统调用的返回值，而新进程的堆栈已经和原进程完全相同，因此会和原进程在相同的位置返回。到这里，也就得到了我们在第1节看到的结果：子进程将进入<code>pid == 0</code>的分支。</p>
<h1 id="3-用gdb跟踪fork"><a href="#3-用gdb跟踪fork" class="headerlink" title="3 用gdb跟踪fork"></a>3 用gdb跟踪fork</h1><p>本节中，我们用gdb跟踪fork函数，以验证我们前面的结论。这里的实验平台采用<a href="https://shiyanlou.com/courses/195" target="_blank" rel="external">实验楼Linux内核分析</a>的第6个实验：分析linux内核创建一个新进程的过程。<br>进入实验平台，输入如下代码：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">cd LinuxKernel</span><br><span class="line">rm menu -rf</span><br><span class="line">git clone https://github.com/mengning/menu.git权威指南</span><br><span class="line">cd menu</span><br><span class="line">mv test_fork.c test.c</span><br><span class="line">make rootfs</span><br></pre></td></tr></table></figure></p>
<p>即可看到启动的实验系统，在系统中输入fork命令，则可以看到如下运行结果：<br><img src="/images/linux-fork/linux-fork-process.jpg" alt="实验系统fork"><br>为了能够用gdb跟踪，输入如下命令：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">qemu -kernel linux-3.18.6/arch/x86/boot/bzImage -initrd ../rootfs.img -s -S</span><br></pre></td></tr></table></figure></p>
<p>再重启一个窗口，输入如下命令：<br><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> ~/LinuxKernel</span><br><span class="line">gdb</span><br><span class="line">file linux-3.18.6/vmlinux</span><br><span class="line">target remote:1234</span><br><span class="line">c <span class="comment">#让程序执行一步</span></span><br><span class="line">^C <span class="comment">#中断程序</span></span><br><span class="line"> <span class="comment">#设置断点</span></span><br><span class="line">b <span class="keyword">do</span>_fork</span><br><span class="line">b copy_process</span><br><span class="line">b dup_task_struct</span><br><span class="line">b copy_thread</span><br><span class="line">b ret_from_fork</span><br><span class="line">c</span><br></pre></td></tr></table></figure></p>
<p>设置以上断点后，在模拟系统的控制台下键入fork，就可以通过断点跟踪fork的执行过程。这里就不展示所有的截图了，大致如下图：<br><img src="/images/linux-fork/linux-fork-break.jpg" alt="断点跟踪"></p>
<h1 id="4-小结"><a href="#4-小结" class="headerlink" title="4 小结"></a>4 小结</h1><p>Linux调用fork复制一个新进程需要经过如下步骤：</p>
<ol>
<li>进入系统中断，调用sys_fork函数</li>
<li>sys_fork调用do_fork函数</li>
<li>do_fork调用copy_process函数</li>
<li>copy_process调用dup_task_struct函数，将父进程的task_struct拷贝给子进程，并为子进程创建单独的进程控制块和内核堆栈空间。新的进程就在这里诞生了。</li>
<li>copy_process调用copy_thread函数，把父进程的堆栈信息复制给子进程，并将ax寄存器设置为0。然后，子进程的入口地点被设置为<code>ret_from_fork</code>标签。</li>
<li>父进程的系统调用逐层返回，返回值为子进程的pid。</li>
<li>子进程在获得CPU控制权时，会执行<code>ret_from_fork</code>，而<code>ret_from_fork</code>会跳转到<code>syscall_exit</code>标签，退出中断。由于<code>ax</code>设置为0，所以系统调用返回0。</li>
</ol>
]]></content>
      
        <categories>
            
            <category> linux </category>
            
            <category> 源码 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> linux </tag>
            
            <tag> 源码 </tag>
            
            <tag> fork </tag>
            
            <tag> 进程创建 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Linux系统调用：32位和64位的区别]]></title>
      <url>/articles/asm-syscall-64.html</url>
      <content type="html"><![CDATA[<p>最近在学习系统调用，一段用asm内联汇编写的简单程序始终得不出正确的结果，后来了解到这是32位平台和64位平台的系统调用方法不同的原因。在此列出相关的程序和我的理解。<br><a id="more"></a><br>原创内容：cxsmarkchan<br>转载请注明出处<br>首次发表于csdn：<a href="http://blog.csdn.net/cxsmarkchan/article/details/50987222" target="_blank" rel="external">Linux asm系统调用：32位和64位的区别</a></p>
<h1 id="程序代码和问题"><a href="#程序代码和问题" class="headerlink" title="程序代码和问题"></a>程序代码和问题</h1><p>首先看如下一段简单的C程序（<code>test.cpp</code>）：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;unistd.h&gt;</span></span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">	<span class="keyword">char</span> str[] = <span class="string">"Hello\n"</span>;</span><br><span class="line">	write(<span class="number">0</span>, str, <span class="number">6</span>);</span><br><span class="line">	<span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>这段程序调用了write函数，其接口为：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">int write(int fd /*输出位置句柄*/, const char* src /*输出首地址*/， int len /*长度*/)</span><br></pre></td></tr></table></figure></p>
<p>fd为0则表示输出到控制台。因此上述程序的执行结果为：向控制台输出一个长度为6的字符串<code>&quot;Hello\n&quot;</code>。<br>在控制台调用<code>gcc test.cpp</code>，可以正确输出。<br>为了更好地理解在汇编代码下的系统调用过程，可把上述代码改写成内联汇编的格式（具体语法可参考上一篇博客：<a href="http://cxsmarkchan.github.io/2016/04/01/asm-syscall" target="_blank" rel="external">用asm内联汇编实现系统调用</a>）：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">//test_asm_A.cpp</span><br><span class="line">int main()&#123;</span><br><span class="line">	char str[] = &quot;Hello\n&quot;;</span><br><span class="line">	asm volatile(</span><br><span class="line">		&quot;int $0x80\n\t&quot;</span><br><span class="line">		:</span><br><span class="line">		:&quot;a&quot;(4), &quot;b&quot;(0), &quot;c&quot;(str), &quot;d&quot;(6)</span><br><span class="line">		);</span><br><span class="line">	return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>其中，4是write函数的系统调用号，ebx/ecx/edx是系统调用的前三个参数。<br><strong>然而，执行<code>gcc test_asm_A.cpp</code>编译后，再运行程序，发现程序没有任何输出</strong>。一个很奇怪的问题是，如果采用如下<code>test_asm_B.cpp</code>的写法，则程序可以正常地输出：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">//test_asm_B.cpp</span><br><span class="line">#include &lt;stdlib.h&gt;</span><br><span class="line">#include &lt;</span><br><span class="line">int main()&#123;</span><br><span class="line">	char *str = (char*)malloc(7 * sizeof(char));</span><br><span class="line">	strcpy(str, &quot;Hello\n&quot;);</span><br><span class="line">	asm volatile(</span><br><span class="line">		&quot;int $0x80\n\t&quot;</span><br><span class="line">		:</span><br><span class="line">		:&quot;a&quot;(4), &quot;b&quot;(0), &quot;c&quot;(str), &quot;d&quot;(6)</span><br><span class="line">		);</span><br><span class="line">	free(str);</span><br><span class="line">	return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p><strong>两段代码唯一的区别，是<code>test_asm_A.cpp</code>中的<code>str</code>存储在栈空间，而<code>test_asm_B.cpp</code>中的<code>str</code>存储在堆空间。</strong><br>那么，为什么存储位置的不同会造成完全不同的结果呢？</p>
<h1 id="原因分析"><a href="#原因分析" class="headerlink" title="原因分析"></a>原因分析</h1><p>经过提醒，将上述代码用32位的方式编译，即<code>gcc test_asm_A.cpp -m32</code>和<code>gcc test_asm_B.cpp -m32</code>，可以发现两段代码都能正确输出。这说明，上述代码按32位编译，可以得到正确的结果。<br>如果没有<code>-m32</code>标志，则gcc默认按照64位方式编译。32位和64位程序在编译时有如下区别：</p>
<ul>
<li>32位和64位程序的地址空间范围不同。</li>
<li>32位和64位程序的系统调用号不同，如本例中的write，在32位系统中调用号为4，在64位系统中则为1。</li>
<li>对于32位程序，应调用<code>int $0x80</code>进入系统调用，将系统调用号传入<code>eax</code>，各个参数按照<code>ebx</code>、<code>ecx</code>、<code>edx</code>的顺序传递到寄存器中，系统调用返回值储存到<code>eax</code>寄存器。</li>
<li>对于64位程序，应调用<code>syscall</code>进入系统调用，将系统调用号传入<code>rax</code>，各个参数按照<code>rdi</code>、<code>rsi</code>、<code>rdx</code>的顺序传递到寄存器中，系统调用返回值储存到<code>rax</code>寄存器。</li>
</ul>
<p>再看上面两段代码，它们都是调用<code>int $0x80</code>进入系统调用，却按照64位方式编译，则会出现如下不正常情形：</p>
<ul>
<li>程序的地址空间是64位地址空间。</li>
<li>0x80号中断进入的是32位系统调用函数，因此仍按照32位的方式来解释系统调用，即所有寄存器只考虑低32位的值。</li>
</ul>
<p>再看程序中传入的各个参数，系统调用号（4），第1个和第3个参数（0和6）都是32位以内的，但是<strong>str的地址是64位地址，在0x80系统调用中只有低32位会被考虑。</strong><br>这样，<code>test_asm_A.cpp</code>不能正确执行，而<code>test_asm_B.cpp</code>可以正确执行的原因就很明确了：</p>
<ul>
<li>在<code>test_asm_A.cpp</code>中，str存储在栈空间中，而<strong>栈空间在系统的高位，只取低32位地址，得到的是错误地址。</strong></li>
<li>在<code>test_asm_B.cpp</code>中，str存储在堆空间中，而<strong>堆空间在系统的低位开始，在这样一个小程序中，str地址的高32位为0，只有低32位存在非零值，因此不会出现截断错误。</strong></li>
</ul>
<p>可见，<code>test_asm_B.cpp</code>正确执行只是一个假象。由于堆空间从低位开始，如果开辟空间过多，堆空间也进入高位的时候，这段代码同样可能出错。</p>
<h1 id="64位系统的系统调用代码"><a href="#64位系统的系统调用代码" class="headerlink" title="64位系统的系统调用代码"></a>64位系统的系统调用代码</h1><p>最后，给出64位系统下可正确输出的asm系统调用代码：<br><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">//test_asm_C.cpp</span><br><span class="line">int main()&#123;</span><br><span class="line">	char str[] = "Hello\n";</span><br><span class="line">	//注意：64位系统调用中，write函数调用号为1</span><br><span class="line">	asm volatile(</span><br><span class="line">		"mov %2, %%rsi\n\t"</span><br><span class="line">		"syscall"</span><br><span class="line">		:</span><br><span class="line">		:"a"(1), "D"(0), "b"(str), "d"(6)</span><br><span class="line">		);</span><br><span class="line">	return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
]]></content>
      
        <categories>
            
            <category> linux </category>
            
            <category> 内核 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> asm </tag>
            
            <tag> 系统调用 </tag>
            
            <tag> linux </tag>
            
            <tag> 64位 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[用asm内联汇编实现系统调用]]></title>
      <url>/articles/asm-syscall.html</url>
      <content type="html"><![CDATA[<p>CPU运行状态被分为内核态和用户态。操作系统在内核态下运行，拥有所有计算机资源的操作权限。而一般的应用程序则在用户态下运行，它们不能直接操作底层的硬件设备。应用程序在需要使用硬件资源时，可通过系统调用（system call）切换到内核态。本文通过asm内联汇编，分析系统调用的全过程。<br><a id="more"></a></p>
<p>原创内容：cxsmarkchan<br>转载请注明出处<br>首次发表于csdn：<a href="http://blog.csdn.net/cxsmarkchan/article/details/50939769" target="_blank" rel="external">用asm内联汇编实现系统调用</a><br><a href="http://mooc.study.163.com/course/USTC-1000029000" target="_blank" rel="external">《Linux内核分析》MOOC课程</a>学习笔记</p>
<h1 id="1-系统调用的概念"><a href="#1-系统调用的概念" class="headerlink" title="1 系统调用的概念"></a>1 系统调用的概念</h1><p>下图是一个典型的系统调用图示：<br><img src="http://img.blog.csdn.net/20160320231125982" alt="这里写图片描述"><br>从该函数可以看到，系统调用分成如下过程：</p>
<ol>
<li>用户态程序调用API函数<code>xyz</code></li>
<li>在<code>xyz</code>接口函数内部，通过中断号<code>0x80</code>进入系统调用，此时CPU进入内核态。</li>
<li>CPU开始执行中断处理程序，根据用户传入的信息（系统调用号和相关参数），执行相应的内核态函数，并返回结果。<br>这里有两个问题：</li>
<li>内核态的切换是通过中断方式进入的，而产生中断时只能传入一个中断向量（即<code>0x80</code>），而系统调用有大量的API函数，系统如何知道调用哪一个函数呢？</li>
<li>有一些API函数带有参数，而系统调用并没有才有函数调用（<code>call</code>）方式，那么参数如何传递到被调用函数？<br>答案是：在调用<code>int 0x80</code>进入系统调用前，预先把系统调用号和相关参数存入指定的寄存器中。这样，系统调用函数只需要访问相应的寄存器，就可以获得所有的信息。<br>事实上，在进入系统调用前，首先需要将系统调用号传入<code>eax</code>寄存器中，并将参数依次传入<code>ebx</code>、<code>ecx</code>、<code>edx</code>、<code>esi</code>、<code>edi</code>、<code>ebp</code>寄存器中。系统调用最多只能传入6个参数，如果参数多于6个，则需要将参数预存在内存中，然后将参数指针传入寄存器。系统调用结束后，<code>eax</code>会被替换为系统调用返回值。</li>
</ol>
<h1 id="2-用asm实现系统调用的实例"><a href="#2-用asm实现系统调用的实例" class="headerlink" title="2 用asm实现系统调用的实例"></a>2 用asm实现系统调用的实例</h1><p>本文运行平台为<a href="https://www.shiyanlou.com/courses/195" target="_blank" rel="external">实验楼Linux内核分析</a>的第4个实验，运行环境为linux系统。<br>为了验证系统调用的全过程，我们以exit函数为例，给出代码如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">#include &lt;stdio.h&gt;</span><br><span class="line">#include &lt;stdlib.h&gt;</span><br><span class="line">int main()&#123;</span><br><span class="line">    int id;</span><br><span class="line">    scanf(&quot;%d&quot;, &amp;id);</span><br><span class="line">    switch(id)&#123;</span><br><span class="line">        case 0:</span><br><span class="line">	        //用C语言的方式调用exit函数</span><br><span class="line">            printf(&quot;C exit\n&quot;);</span><br><span class="line">            exit(0);</span><br><span class="line">            break;</span><br><span class="line">        case 1:</span><br><span class="line">	        //用内联汇编的方式调用exit函数</span><br><span class="line">            printf(&quot;asm exit\n&quot;);</span><br><span class="line">            asm volatile(</span><br><span class="line">                    &quot;mov $0, %%ebx\n\t&quot;</span><br><span class="line">                    &quot;mov $0x1, %%eax\n\t&quot;</span><br><span class="line">                    &quot;int $0x80\n\t&quot;</span><br><span class="line">                    :</span><br><span class="line">                    :</span><br><span class="line">                    );</span><br><span class="line">            break;</span><br><span class="line">        default:</span><br><span class="line">            printf(&quot;others\n&quot;);</span><br><span class="line">            break;</span><br><span class="line">    &#125;</span><br><span class="line">    printf(&quot;before return\n&quot;);</span><br><span class="line">    return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>该函数中，首先输入参数id。如果id为0，则调用C代码的exit函数。如果id为1，则调用汇编代码的exit函数。如果id为其他值，则顺序执行至main函数结尾。<br>事实上，上文的代码采用C代码和内联汇编实现了等价的功能，即<code>exit(0)</code>功能。可以分析一下内联汇编的工作方式：</p>
<ol>
<li><code>mov $0, %ebx</code>：exit函数的第1个参数（也是唯一一个参数）为0，按照寄存器顺序，应该放在<code>ebx</code>中。</li>
<li><code>mov $0x1, %eax</code>：exit函数的系统调用号为<code>0x1</code>，因此把系统调用号放入<code>eax</code>中。</li>
<li><code>int 0x80</code>：产生中断，中断号<code>0x80</code>表示系统调用。<br>执行了以上3步，即为执行了exit(0)函数。程序的运行结果如下：<br><img src="http://img.blog.csdn.net/20160320233359080" alt="这里写图片描述"><br>可见，输入0或1时，都没有输出<code>&quot;before return&quot;</code>，说明exit被成功调用，程序提前退出。</li>
</ol>
<h1 id="3-小结"><a href="#3-小结" class="headerlink" title="3 小结"></a>3 小结</h1><p>系统调用既保证了操作系统的安全运行，也方便了用户态程序使用系统资源。用内联汇编的方式处理系统调用，可以很清晰地看出系统调用的过程，以及系统调用的参数传递方式。系统调用通过寄存器传递参数，因此在进行系统调用前，通常还需要备份相关寄存器中的信息。不过，在内联汇编中，这个工作会被编译器代劳。</p>
]]></content>
      
        <categories>
            
            <category> linux </category>
            
            <category> 内核 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 操作系统 </tag>
            
            <tag> 汇编 </tag>
            
            <tag> asm </tag>
            
            <tag> 系统调用 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[第一篇博客]]></title>
      <url>/articles/firstblog.html</url>
      <content type="html"><![CDATA[<p>&emsp;&emsp;博士入学已经一年半了，走过不少弯路，也算有一些成长。一直想抽时间做个博客，记录自己的学习和科研生活，最近终于付诸行动。<br><a id="more"></a></p>
<p>&emsp;&emsp;电气工程是一个和计算机结合紧密的专业，我在做电力系统方向的科研时，也常常需要设计算法、编写程序。不过，直到去年，在董老师和浩哥的带领下，我才对码农的世界有了更多的了解，也越来越觉得自己如井底之蛙一般。因此，也希望更系统、更深入地学习计算机科学的知识，并将其融入到自己的科研中。</p>
<p>&emsp;&emsp;我会在这里记录自己的学习和思考，努力进步。</p>
<p>&emsp;&emsp;最后，希望自己能坚持下去^_^</p>
<p>&emsp;&emsp;PS: 该博客用<a href="https://hexo.io" target="_blank" rel="external">Hexo</a>搭建。</p>
<p>&emsp;&emsp;PPS: 之前在csdn上写过几篇博客，如果有空的话也会迁移过来。</p>
]]></content>
      
        <categories>
            
            <category> 生活 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 博客 </tag>
            
            <tag> hexo </tag>
            
        </tags>
        
    </entry>
    
  
  
    
    <entry>
      <title></title>
      <url>/baidu_verify_K2nP6IxHJn.html</url>
      <content type="html"><![CDATA[K2nP6IxHJn
]]></content>
    </entry>
    
    <entry>
      <title></title>
      <url>/baidu_verify_iZA6IpYgQU.html</url>
      <content type="html"><![CDATA[iZA6IpYgQU
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[关于]]></title>
      <url>/about/index.html</url>
      <content type="html"><![CDATA[<!--
- 2014.09至今 清华大学 电气工程及其自动化 博士学位在读
- 2010.09-2014.07 清华大学 电气工程及其自动化 学士学位
- 2011.09-2014.07 清华大学 经济学 第二学士学位
-->
<!--
# 教育背景
- 2014.09至今 清华大学 电气工程及其自动化 博士学位在读
- 2010.09-2014.07 清华大学 电气工程及其自动化 学士学位
- 2011.09-2014.07 清华大学 经济学 第二学士学位

# 研究领域
- 电力系统优化算法
- 风电消纳技术

# 论文发表
- **Xiaoshuang Chen**, Jin Lin, Can Wan _et al_, "Optimal Meter Placement for Distribution Network State Estimation: A Circuit Representation Based MILP Approach," in _IEEE Transactions on Power Systems_, Early Access(**SCI**: 20160501869988)
- **陈晓爽**,林今,宋永华. 配电网状态估计误差的电路表示方法[J]. 中国电机工程学报,2014,28:4839-4846.(**EI**:20144400132409)

-->
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[读书]]></title>
      <url>/reading/index.html</url>
      <content type="html"></content>
    </entry>
    
  
</search>
